# Buffer Pool

The DBMS is responsible for managing its memory and moving data back-and-forth from the disk

Database must be able to efficiently move data represented as files on its disk into memory so that it can be used

因为数据无法直接在磁盘上被使用，所以 DBMS 需要将数据以文件的格式读取到内存中

同时 DBMS 还需要尽可能减少磁盘读取带来的延时



#### Spatial Control

Refers to where pages are physically written on disk

To consider where to write pages on disk - Physically

The goal of spatial control is to keep pages that are used together often as physically close together as possible on disk

考虑改变磁盘上 pages 的排列



#### Temporal Control

When to read pages into memory, and when to write them to disk

The goal is to minimize the number of stalls from having to read data from disk



## Locks VS. Latches

We need to make a distinction between locks and latches when discussing how the DBMS protects its internal elements



**Locks:**

+ Higher-level, logical primitive that protects the contents of a database from other transactions
+ Database system can expose to the user which locks are being held as queries are run
+ Locks need to be able to rollback changes



**Latches:**

+ Low-level protection primitive that the DBMS uses for the critical sections in its internal data structures
+ Held for only the duration of the operating being made
+ Do not need to be able to rollback changes



## Buffer Pool Organization

Memory region organized as an array of fixed-size pages - Buffer Pool

An array entry is called a **frame**

When the DBMS requests a page, an exact copy is placed into one of these frames

The **page table** keeps track of pages that are currently in memory

Also maintains additional meta-data per page like **dirty flag** and **Pin/Reference counter**



Buffer Pool：一个固定长度的数组，数组有 frame  组成，每一个 frame 存储一个 page

DBMS 会将被调用的 page 从磁盘中复制到 frame 中

DBMS 同时会在内存中维护一个 page table 用来记录哪些 page 正在内存中



### Page Table

Is an in-memory hash table that keeps track of pages that are currently in memory

It maps page ids to frame locations in the buffer pool



Dirty flag: set by thread whenever it modifies a page, indicates to storage manager that the page must be written back to disk

Pin/reference Counter: tracks the number of threads that are currently accessing that page. Reference counter is incremented when used



### Allocation policy

**Global:** 

Manage buffer pool globally when all transactions concurrently

Consider all active transactions to find an optimal decision for allocating memory



**Local:**

For single query

Allocate frames to a specific transactions without considering the behavior of concurrent transactions



## Buffer Pool Optimization

### 1. Multiple Buffer Pool

DBMS does not always have a single buffer pool for the entire system

+ Multiple buffer pool instances
+ Per-database buffer pool
+ Per-page type buffer pool



Helps reduce latch contention and improve locality



Problem: How much space to allocate for each buffer pool?

Multiple pages in different buffer pool -> need to make sure to map page one - to - one buffer pool



#### Approach #1: Object Id

Embed an object identifier in record ids and then maintain a mapping from objects to specific buffer pools

Then through the object identifier, a mapping from objects to specific buffer pools can be maintained



#### Approach #2: Hashing

Hash the page id to select which buffer pool to access



### 2. Pre-Fetching

The DBMS can also prefetch pages based on a query plan

+ Sequential Scans
  + 顺序将 Pages 从磁盘中添加进 Buffer Pool
  + 当接近 Buffer Pool 底部的时候将下一个的下一个 Page 替换到 Buffer Pool 首部的位置
+ Index Scans
  + 由系统维护并可用于所有的 query
  + 使用 B+ Tree 将整个 Pages 进行排序
  + 对 Tree 进行遍历找到需要的 index



### 3. Scan Sharing

Queries can reuse data retrieved from storage or operator computations

+ Also called *synchronized scans*
+ Different from result caching



Allow multiple queries to attach to a single cursor that scan a table

+ Queries do not have to be the same
+ Can also share intermediate results



If a query wants to scan a table and another query is already doing this, then the DBMS will attach the second query's cursor to the existing cursor

如果有一个 query Q1 已经扫描过表中部分数据，那么如果一个查找相同表的 query Q2 进来时

只需要先将 Q2 和 Q1 合并扫描 Q1 剩余的部分

再将 Q2 重新扫描之前未扫描的部分



**Question: **Multiple queries running at the same time, which one to choose to attach

A: Different trade offs, better to attach the one that scan through from the beginning to the end



**Question: **Do you have to stall the query when attach to it?

A: Yes, it is worth to wait for it than waiting for disk to make page out



### 4. Buffer Pool Bypass

The sequential scan operator will not store fetched pages in the buffer pool to avoid overhead

+ Memory is local to running query
+ Works well if operator needs to read a large sequence of pages that are contiguous on disk
+ Can also be used for temporary data

"Light scan": A light scan bypasses the buffer pool by utilizing session memory to read directly from disk



### OS Page Cache

OS maintains its own filesystem cache

Most DBMS used direct I/O to bypass the OS's page cache

+ Redundant copies of pages
+ Different eviction policies
+ Loss of control over file I/O



## Buffer Replacement Policies

When the DBMS needs to free up a frame to make room for a new page, it must decide which page to evict from the buffer pool



Goals:

+ Correctness
+ Accuracy
+ Speed
+ Meta - data Overhead



### Least - Recently Used (LRU)

LRU maintain a single timestamp of when each page was last accessed



When the DBMS needs to evict a page, select the one with the oldest timestamp

+ Keep the pages in sorted order to reduce the search time on eviction



### Clock

Approximation of LRU that does not need a separate timestamp per page

+ Each page has a **reference bit**
+ When a page is accessed, set to 1



Organize the pages in a circular buffer with a "clock hand"

+ Upon sweeping, check if a page's bit is set to 1
+ If yes, set to zero. If no, then evict



Only need to allocate one bit rather than the entire timestamp for each page

A fixed - size array in buffer pool for all frames



### Problems

LRU and CLOCK replacement policies are susceptible to *sequential flooding*

Sequential scans read every page, the timestamps of pages read my not reflect which pages we actually want



Three solutions to address the shortcomings of LRU and CLOCK policies:

+ LRU-K
  + Tracks the history of last K references as timestamps and computes the interval between subsequence accesses
  + Used to predict the next time a page is going to be accessed
+ Localization
  + DBMS chooses which pages to evict on a per transaction/query basis
  + Minimizes the pollution of the buffer pool from each query
+ Priority hints
  + Allow transactions to tell the buffer pool whether page is important or not based on the context of each page during query execution



## Dirty Pages

Two methods to handling pages with dirty bits

Fastest option is to drop any page in the buffer pool that is not dirty

Slower method is to write dirty pages to disk to ensure that its changes are persisted



Trad-off between fast evictions versus dirty writing pages that will not be read again in the future



**Background writing:** DBMS periodically walk through the page table and write dirty pages to disk

When dirty page is safely written, the DBMS can either evict the page or just unset the dirty flag







