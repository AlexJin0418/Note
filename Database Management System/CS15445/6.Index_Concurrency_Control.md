# Index Concurrency Control

## Questions from last class

+ Non-prefix lookups in multi-attribute B+ Trees
  + Skip Scan: Find subsequences that target value is in range
+ Efficiently merging B+ Trees
  + Off-line:
    + Block all operations until done merging
  + Eager:
    + Access both during merge; move batches eagerly
  + Background:
    + Copy + merge in background; apply missed updates
  + Lazy:
    + Designate one as main and other as secondary
    + If leaf in main not yet updated, merge corresponding key range from secondary



## Concurrency Control

We need to allow multiple threads to safely access data structures

A **Concurrency control** protocol is the method that the DBMS uses to ensure "correct" result for concurrent operations on a shared object



A protocol's correctness criteria can vary:

+ **Logical Correctness:** Thread is able to read values that it should expects to read
+ **Physical Correctness:**  Internal representation of the object is sound - pointers should always lead to valid memory location



## Locks vs. Latches

There is an important distinction between locks and latches when discussing how the DBMS protects its internal elements



### Locks

+ Higher-level, logical primitive that protects the contents of a database - tuples, tables, database
+ Transactions will hold a lock for its entire duration
+ Database systems can expose to the user the locks that are being held as queries are run
+  Locks need to be able to rollback changes

### Latches

+ Low-level protection primitives used for critical sections the DBMS’s internal data structures from other threads - regions of memory
+ Latches are held for only the duration of the operation being made
+ Latches do not need to be able to rollback changes
+ Two modes for latches:
  + **READ:** Multiple threads are allowed to read the same item at the same time; A thread can acquire the read latch even if another thread has acquired as well; A thread cannot acquire read latch if another thread holds a write latch
  + **WRITE:** Only one thread is allowed to access the item; A thread cannot acquire a write latch if another thread holds the latch in any mode; A threading holding a write latch also prevents other threads from acquiring a read latch



## Latch Implementations

### 1. Blocking OS Mutex

Simple to use

Non-scalable

```C++
std::mutex m;
//...

m.lock();
// Do somthing special
m.unlock();
```



Linux provides the `futex` (fast user-space mutex), which is comprised:

+ A spin latch in user-space 
+ An OS-level mutex

It appears as a single latch to the DBMS even though it contains two internal latches

If the DBMS fails to acquire the user-space latch, then it goes down into the kernel and tries to acquire a more expensive mutex

If the DBMS fails to acquire this second mutex, then the thread notifies the OS that it is blocked on the mutex and then it is de-scheduled



OS mutex is generally a **bad idea** inside of DBMSs as it is managed by OS and has large overhead



### 2. Test - and - Set Spin Latch (TAS)

Spin latches are a more efficient alternative to an OS mutex as it is controlled by the DBMSs

A spin latch is essentially a location in memory that threads try to update - setting a bool value to true

A thread performs CAS to attempt to update the memory location

The DBMS can control what happens if it fails to get the latch

It can choose to try again  or allow the OS to reschedule it



**Disadvantages**

Not scalable nor cache-friendly because with multiple threads, the CAS instructions will be executed multiple times in different threads. These wasted instructions will pile up in high contention environments; the threads look busy to the OS even though they are not doing useful work. This leads to cache coherence problems because threads are polling cache lines on other CPUs.



**\*\*DO NOT USE SPINLOCKS IN USER SPACE UNLESS YOU ACTUALLY KNOW WHAT YOU'RE DOING\*\***



### 3. Reader - Writer Latches

A Reader-Writer Latch allows a latch to be held in either read or write mode

It keeps track of how many threads hold the latch and are waiting to acquire the latch in each mode

Reader-writer latches use one of the previous two latch implementations as primitives and have additional logic to handle reader-writer queues



**Disadvantages**

The DBMS has to manage read/write queues to avoid starvation - Read latches building up where write latches cannot acquire the latch

Larger storage overhead than Spin Latches due to additional meta-data



### 4. Hash Table Latching

Easy to support concurrent access in a static hash table due to the limited ways threads access the data

All threads move in the same direction when moving from slot to the next

Threads also only access a single page/slot at a time

Deadlocks are not possible in this situation because no two threads could be competing for latches held by the other



#### Approach #1: Page Latches

+ Each page has its own Reader-Writer latch that protects its entire contents
+  Threads acquire either a read or write latch before they access a page

#### Approach #2: Slot Latches

+ Each slot has its own latch
+ Increases parallelism because two threads can access different slots on the same page



### 5. B+ Tree Latching

The challenge of B+Tree latching is preventing the two following problems:

+ Threads trying to modify the contents of a node at the same time
+ One thread traversing the tree while another thread splits/merges nodes



Latch crabbing/coupling is a protocol to allow multiple threads to access/modify B+Tree at the same time.

+ Get latch for the parent
+ Get latch for the child
+ Release latch for the parent if it is deemed “safe”; A “safe” node is one that will not split or merge when updated

**Basic Latch Crabbing Protocol:**

+ **Search:** Start at the root and go down, repeatedly acquire latch on the child and then unlatch parent
+ **Insert/Delete:** Start at the root and go down, obtaining X latches as needed. Once the child is latched, check if it is safe. If the child is safe, release latches on all its ancestors - For performing reason it is better to release from the order that acquired



The notion of “safe” also depends on whether the operation is an insertion or a deletion

A full node is “safe” for deletion since a merge will not be needed but is not “safe” for an insertion since we may need to split the node



What was the first step that all the update examples did on the B+ Tree?

Taking a write latch on the root every time becomes a **bottleneck** with higher concurrency



#### Improve Latch Crabbing Protocol

The problem with the basic latch crabbing algorithm is that transactions always acquire an exclusive latch on the root for every insert/delete operation

Transactions can acquire shared latches down to the leaf nodes

Each transaction will assume that the path to the target leaf node is safe, and use READ latches and crabbing to reach it and verify

 If the leaf node is not safe, then we abort and do the previous algorithm where we acquire WRITE latches

先假设整个过程是 safe 的，使用 read 锁，如果是不安全的，则从头开始使用 write 锁

+ **Search:** Same algorithm as before
+ **Insert/Delete:** Set READ latches as if for search, go to leaf, and set WRITE latch on leaf. If the leaf is not safe, release all previous latches, and restart the transaction using previous Insert/Delete protocol



#### Lead Node Scan

The threads in these protocols acquire latches in a “top-down” manner

This means that a thread can only acquire a latch from a node that is below its current node



**But what if we want to move from one leaf node to another leaf node?**

Leaf node scans are susceptible to deadlocks because now we have threads trying to acquire locks in two different directions at the same time

Index latches do not support deadlock detection or avoidance



B+ Tree must cope with failed latch acquisitions: If a thread tries to acquire on a leaf node but that latch is unavailable, then **it will immediately abort its operation and then restart the operation**







