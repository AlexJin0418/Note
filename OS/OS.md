# 第3章 内存管理
**分层存储体系 (memory hierarchy):**
+ 若干兆(MB)，快速，昂贵且易丢失的高速缓存(cache)
+ 数千兆(GB)，速度与价格适中且同样易丢失的内存(memory)
+ 几兆兆(TB)，低速，廉价，非易丢失的磁盘存储(disk)

**存储管理器 (memory manager):** 管理分层存储器体系。记录内存的使用情况，为进程分配和释放内存。

## 3.1 无存储器抽象
最简单的存储器抽象就是根本没有抽象，每一个程序都直接访问物理内存
`问题：1. 如果用户程序可以寻址内存的每一个字节，那么就可以很容易地破坏操作系统。2. 运行多个程序是很困难的。`

**在不使用存储器抽象的情况下运行多个程序**

**1. 交换概念：** 操作系统只需要把当前内存中所有内容保存到磁盘文件中，然后把下一个程序读入到内存中再运行即可。只要在某一个时间内内存中只有一个程序，那么就不会发生冲突

**2. 特殊硬件：** IBM 360早期模型使用一个存储在CPU特殊寄存器中的4位**保护键**，进程如果访问保护键与其程序状态字不同的内存，360的硬件会捕获这一事件。

`问题：两个程序都引用了绝对物理地址`
两个程序因为内存键不同会被装载到不同的内存地址，但是指令都是引用绝对物理地址，所以两个程序很可能会对相同的物理地址进行修改，导致程序崩溃。

**解决办法：** 使用**静态重定位**的技术修改后装载程序的地址，将程序起始的物理地址加到每一个程序地址上。但是运行程序需要提供额外的信息来区分哪些字是**常数**，哪些字是**可重定位地址**，并且重定位会减慢装载速度。

## 3.2 一种存储器抽象: 地址空间

### 3.2.1 地址空间的概念
保护键无法完美解决多个应用程序处于内存中互不影响的问题，一个更好的办法是创造一个新的存储器抽象：**地址空间**。
> **地址空间**是一个进程可用于寻址内存的一套地址集合。每一个进程都有一个自己的地址空间，并且这个地址空间独立于其他进程的地址空间。

**基址寄存器与界限寄存器：** 使用**动态重定位**，把每一个进程的地址空间映射到物理内存的不同部分。两个特殊的CPU硬件寄存器
+ 基址寄存器：装载程序的起始物理地址
+ 界限寄存器：装载程序的长度

在进程访问内存时，CPU硬件会首先将基址值加到进程发出的地址值上，同时检查程序提供的地址是否等于或大于界限寄存器中的值。

`缺点：每次访问内存都需要进行加法和比较的运算。加法运算由于进位传递的问题会显得很慢。`

### 3.2.2 交换技术
如果计算机的物理内存足够大，可以保存所有进程，那么之前所提及的方案或多或少都是可行的。但是很多程序开始处理数据之后可能需要数千兆的空间，所以把所有进程一直保存在内存中需要巨大的内存，如果内存不够大就会导致`内存超载`。

有两种方法处理内存超载：**交换(swapping)技术**，即把进程调用内存中运行一段时间后存回磁盘。另一种是**虚拟内存 (virtual memory)**，使程序在只有一部分被调入内存的情况下运行。

**内存紧缩 (memory compaction)：** 在交换内存的过程中产生了多个空闲区，通过把所有的进程尽可能向下移动，有可能将这些小的空闲区合成一大块。通常不进行这个操作，因为它要耗费大量的CPU时间。 

`问题：如果进程创建时其大小是固定的并且不会改变，则分配很简单。但如果进程需要在堆中动态地分配内存，那么进程空间增长时就面临获取更多空闲空间的问题。`
一种可行的方法是，当换入或移动进程时提前为它分配一些额外的内存供其堆栈段进行增长。

### 3.2.3 空闲内存管理
在动态分配内存时，操作系统必须对其进行管理。一般有**位图**和**空闲区链表**两种方法。

**1. 使用位图的存储管理**
> 使用位图方法时，内存可能被划分成小到几个字或大到几千字节的分配单元。每个分配单元对应于位图中的一位，0表示空闲，1表示占用（或者相反）。一块内存区和其对应的位图如图3-6所示。
![](https://img-blog.csdnimg.cn/20190414220059645.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxNDc1NzAzOTgw,size_16,color_FFFFFF,t_70)

内存的大小和分配单元的大小决定了位图的大小。这种方法的主要问题是：`在把一个占k个分配单元的进程调入内存时，存储管理器必须所搜位图，在位图中找出k个连续0的串。查找指定长度的连续0串是耗时操作，这时位图的缺点。`

**2. 使用链表的存储管理**
维护一个记录已分配内存段和空闲内存段的链表。其中链表中的一个结点或者包含一个进程，或者是两个进程间的一块空闲区。一个节点包括**空闲区: H** 或者 **进程: P** 的指示标志，**起始地址**，**长度**和**指向下一个节点**的指针。链表使用双向链表可能比单向链表更方便，更易于找到上一个节点。

当按照地址顺序在链表中存放进程和空闲区时，有几种算法可以用来为创建的进程(或从磁盘中换入的已存在的进程)分派内存。
+ **首次适配(first fit)算法:** 沿着段链表从头进行搜索，找到足够大的空闲区域。这种方法速度快。
+ **下次适配(next fit)算法:** 记录每次找到合适空闲区的位置，以便下次寻找空闲区时从上次结束的地方开始搜索。
+ **最佳适配(best fit)算法:** 搜索整个空闲区，找出能够容纳进程的最小空闲区。速度慢且会生成大量无用地小空闲空间。
+ **最差适配(worst fit)算法:** 总是分配最大地可用空闲区，使新的空闲区可以继续使用。
+ **快速适配(quick fit)算法:** 为常用大小的空闲区维护单独的链表。比如链表第一项是指向4kb大小的空闲区的指针，第二项是指向8kb大小的空闲区的指针。快速适配算法能够快速地查找**指定大小的**空闲区。`所有对链表排序的算法都有一个缺点：当一个进程终止或被换出时，寻找它的相邻块并查看是否可以合并的过程是非常费时的(？查看相邻块是否可以合并，如果合并需要重新排序)。如果不进行合并，那内存很快会分裂出大量进程无法使用的小空闲区。`

**对算法速度的优化：** 单独维护进程链表和空闲区链表。这样只用检查空闲区链表，提高算法速度。但会增加复杂度和内存释放速度变慢，因为要将进程链表地回收段删除并插入空闲的区链表。
**对最佳适配算法的优化：** 进程和空闲区使用不同链表，并对空闲区链表按照大小排序，那么最合适的空闲区段就是最小适配的。
**对空闲链表的优化：** 空闲区第一个字可以是空闲区大小，而第二个字可以是指向下一个空闲区的指针。

## 3.3 虚拟内存
计算机的发展导致运行的程序往往大到内存无法容纳，而且必然需要系统能够支持多个程序同时运行。
20世纪60年代的做法是将整个程序分割成许多片段，称为**覆盖(overlay)**。覆盖块存放在磁盘上，在需要时由操作系统动态地换入换出。问题在于程序员必须把程序分割成多个片段。把一个大程序分割成小的，模块化的片段是非常费时和枯燥的，并且易于出错。

**虚拟内存(virtual memory)：** 虚拟内存的基本思想是，每个程序拥有自己的地址空间，这个空间被分割成多个块，每一块称作一**页**或**页面(page)**。每一页有连续的地址范围。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行。

### 3.3.1 分页
由程序产生的这些地址成为**虚拟地址(virtual address)**，它们构成了一个**虚拟地址空间(virtual address space)**。
+ 没有虚拟内存的计算机上，系统直接将虚拟地址送到内存总线上，读写操作使用具有同样地址的物理内存字
+ 有虚拟内存的情况下，虚拟地址不是被直接送到内存总线上，而是被送到**内存管理单元(Memory Management Unit, MMU)**，MMU把虚拟地址映射为物理内存地址

虚拟地址空间按照固定大小划分为被称为**页面(page)**的若干单元。在物理内存中对应的单元成为**页框(page frame)**。页面和页框的大小是一样的。

当程序试图访问一个地址时，首先会将虚拟地址送到MMU。MMU看到虚拟地址后，根据其映射结果，将虚拟地址对应的物理地址送到内存总线上。内存对MMU一无所知，它只看到一个读或者写地址的请求并执行它。MMU有效地把虚拟地址映射到了物理地址上。

`但这并没有解决虚拟地址空间比物理内存大的问题。假设物理页框的数量为8，而虚拟页面的数量为16，那么只有8个虚拟页面能够被映射到物理地址上，而其他8个虚拟页面则没有被映射。`
在实际的硬件中，用一个**在/不在 (present / absent bit)位**记录页面在内存中的实际存在情况。

**如果程序访问了一个未被映射的页面，并执行指令时，将会发生什么情况？**
首先虚拟地址将会被送到MMU。MMU发现这个虚拟地址所在的虚拟页面没有物理页框的映射，于是使CPU陷入到系统操作。这个陷阱被成为**页面中断**或**页面错误(page fault)**。操作系统找到一个很少被使用的页框，并把它的内容写入磁盘。随后把需要访问的页面读到刚才回收的页框中，修改映射关系，然后重新启动引起陷阱的指令。

**MMU的工作机制：** 对于16位地址的计算机，其虚拟地址的范围是0到64K-1。假如虚拟页面的大小是4KB，那么总共就有16个虚拟页面。如果虚拟地址是8196，其对应的二进制为 0010000000000100。我们就可以将这个16位的虚拟地址分为4位的页号和12位的偏移量。4位的页号能够表示16个页面，而12位的偏移量可以为一页内的全部4096个字节编址。可用页号作为**页表(page table)** 的索引，以得出对应于该虚拟页面的页框号。如果“在/不在”位是0，则会引起一个操作系统陷阱。如果虚拟页面有对应的物理页面，那么将对应的页框号复制到寄存器的高3位中，同时加上虚拟地址中12位的偏移量。如此就构成了15位的物理地址。

### 3.3.2 页表
作为最简单的实现，虚拟地址到物理地址的映射可以概括为：虚拟地址被分成虚拟页号(高位部分)和偏移量(地位部分)两部分。对于虚拟地址的划分应对应不同的页面大小。

> 虚拟页号可以作页表的索引，以找到该虚拟页面对应的页表项。由页表项可以找到页框号。然后把页框号拼接到偏移量的高位端，以替换掉虚拟页号，形成送往内存的物理地址。简单来说，页表是一个函数，它的参数是虚拟页号，输出的结果是物理页框号。通过这个函数可以把虚拟地址中的虚拟页面替换成页框域，从而形成物理地址。

**页表项的结构**
![page_table](https://res.cloudinary.com/harlan9613/image/upload/v1586155802/IMG/3-11_bqokj3.png)
不同计算机的页表项大小可能不一样，但32位是一个常用的大小。最重要的是**页框号**。毕竟页映射的目的是找到这个值，其次是“在/不在”位。这一位是1时表示该表项是有效的，如果是0，表示对应的虚拟页面不在内存中，会引起一个缺页中断。

**保护(protectio)** 位指出一个页允许什么类型的访问。最简单的形式是这个域只有一位，0表示读/写，1表示只读。更先进的方法是使用三位，各位分别对应是否启用读，写，执行该页面。

**修改(modified)** 和**访问(referenced)**位，在写入一页时由硬件自动设置修改位。如果一个页面已经被修改过，则必须把它写回磁盘。如过一个页面没有被修改过，那么只需要简单地丢弃掉就可以了。这一位也被叫做**脏位(dirty)**。

访问位地值用来帮助操作系统在发生缺页中断时选择要被淘汰地页面。不再使用地页面要比正在使用地页面更适合淘汰。访问位在页面置换算法中起到很重要地作用。

### 3.3.3 加速分页过程
在任何分页系统中，都需要考虑两个主要的问题：
+ 虚拟地址到物理地址地映射必须非常快。
+ 如果虚拟地址空间很大，页表也会很大。

**1. 转换检测缓冲区 (Translation Lookaside Buffer, TLB)：** 是一个为计算机配备地小型硬件设备。将虚拟地址直接映射到物理地址，而不必再访问页表。这个设备通常在MMU中，包含少量地表项。每个表项记录了一个页面地相关信息，包括虚拟页号，页面的修改位，保护码(读，取，执行权限)和该页所对应地物理页框。
![TLB](https://res.cloudinary.com/harlan9613/image/upload/v1586155802/IMG/3-12_b6wtla.png)

将虚拟地址放入MMU中进行转换时，硬件首先通过将该虚拟页号与TLB中所有表项同时进行匹配，判断该虚拟页面是否在其中。如果发现了一个有效的匹配并且要进行的访问操作并不违反保护位，则将页框号直接从TLB中取出而不必再访问页表。如果虚拟页号确实在TLB中，但指令试图在一个只读页面上进行写操作，则会产生一个错误保护。

如果MMU检测到虚拟页面没有在TLB中，就会进行正常的页表检查。**接着从TLB中淘汰掉一个表项，然后用新找到的页表项代替它**。这样，如果这一个虚拟页表被很快再次访问，第二次访问TLB时就会查询到对应的页框号。被淘汰的页表将修改位复制到内存中的页表项，而除了访问位，其他的值不变。当页表项从页表中装入TLB时。所有的值都来自内存。

**2. 软件TLB管理：**
对TLB的管理和TLB的失效处理都完全由MMU硬件来实现。

许多现在的机器，对页面管理是由软件实现的。TLB表被操作系统显式地装载。
当一个页面访问在内存中而不在TLB时，将产生**软失效(soft miss)**。那么此时要做的就是更新一下TLB。
当一个页面访问即不再内存，也不再TLB时，将产生**硬失效(hard miss)**。此可需要磁盘存取以装入该页面。


### 3.3.4 针对大内存的页表

**1. 多级页表：**
如果一个32位的虚拟地址被分为10位的PT1域，10位的PT2域和12位的Offset(偏移量)。因为偏移量是12位，所以页面大小是4KB，共有2^20个页面。
> 对于32位的CPU来说，能够寻到的最大地址范围为 2^32 个地址。每个地址访问一个Byte，那么地址范围就是 4294967296 Byte = 4GB。
12位的偏移量指的是能表示的数的范围是 [0] - [2^12 - 1]，那么这个范围就是 2^12 = 4K。一位对应一个字节，所以是4KB。
我们共有4GB范围的地址，每一个分页的范围是4KB，那么总共的页面数就是 4GB / 4KB = 2^20。
那么可以通过前20位来确定在 2^20 个页表中的哪一个页表，然后用12位的偏移来确定具体的位置。

引入多级页表的原因是避免把全部页表一直保存在内存中。特别是那些从不需要的页表就不应该保留。
![page_table2](https://res.cloudinary.com/harlan9613/image/upload/v1586155802/IMG/3-13_xrr7n0.png)

上图中，左边是顶级页表，有1024个表项，对应于10位的PT1域。当一个虚拟地址被送到MMU时，MMU首先提取PT1域并把该值作为访问顶级页表的索引。因为**4GB** 的虚拟内存空间被分为了**1024** 个表项，那么每一个表项都表示一块**4MB** 的地址范围。

由索引顶级页表得到的表项中含有二级页表的地址或者页框号。**顶级页表的表项0指向程序正文的页表，表项1指向数据的页表，表项1023指向堆栈的页表，其他表项未用。** 现在把PT2域作为访问选定的二级页表的索引，以便找到该虚拟页面的对应页框号。

值得注意的是，虽然图中的虚拟地址超过100万个页面，实际上只需要四个页表：顶级页表，以及正文段，数据段和堆栈段的二级页表。

图中的二级页表可扩充位三级，四级或者多级。级数越多，灵活性就越大。

**2. 倒排页表**
倒排页表的设计中，实际内存中的每个页框对应一个表项。而不是虚拟页面对应一个表项。
`从虚拟地址到物理地址的转换会变得很困难，需要搜索整个倒排页表来查找某一个表项`
可以使用TLB来记录所有频繁使用的页面。

## 3.4 页面置换算法
当发生页面中断时，操作系统必须在内存中选择一个页面将其换出内存，以便为即将调入的页面腾出空间。
+ 如果换出的页面在内存驻留期间已经被修改过，就必须把它写回磁盘以更新该页面在磁盘上的副本
+ 如果该页面没有被修改过，那么不需要写回磁盘。直接调用页面覆盖被淘汰的页面就可以

### 3.4.1 最优界面置换算法
在缺页中断发生时，有些页面在内存中。每个页面都可以用在该页面首次被访问前索要执行的指令数作为标记。
最优置换算法规定应该置换**标记最大的页面**。
`问题是无法实现的。因为操作系统无法知道各个页面下一次将在什么时候被访问。`

### 3.4.2 最近未使用页面置换算法
**Not Recently Used - NRU**
使用访问位和修改位来构造一个简单的页面置换算法：当启动一个进程时，它的所有页面的两个位都由操作系统设置为0，访问位被定期地清零，以区别最近没有被访问地页面和被访问地页面。
当发生缺页中断时，操作系统检查所有的页面并根据它们地R位和M位地值，把它们分成4类：
+ 第0类：没有被访问，没有被修改
+ 第1类：没有被访问，已被修改
+ 第2类：已被访问，没有被修改
+ 第3类：已被访问，已被修改

因为时钟会不断地将R位清零，所以第2类会变成第0类。不清除修改位是因为在淘汰页面时需要这个信息来判断这个页是否需要从内存写回磁盘记录信息还是直接被覆盖淘汰。

**NRU**算法随机地从类编号最小地非空类中挑选一个页面淘汰。

### 3.4.3 先进先出页面置换算法
**First-in First-out FIFO**
操作系统维护一个所有**当前在内存中地页面**的链表，最新进入的页面放在表尾，最早进入的在表头。发生缺页中断时，淘汰表头的页面并吧新调入的页面加到表尾。
`有可能会淘汰掉常用的页表`

### 3.4.4 第二次机会页面置换算法
对FIFO进行一个修改。判断最早放入链表的页面的R位是不是0，如果是0，那么可以直接被置换掉。如果是1，则将R位清零，并把这个页面重新插入链表，**修改它装入的时间为最新的时间。**

该算法就是寻找一个在最近的时钟间隔内没有被访问过的页面。如果所有的页面都被访问过了，该算法就简化为纯粹的FIFO算法。

### 3.4.5 时钟页面置换算法
把所有的页面保存在一个类似钟面的环形链表中，一个表针指向**最老** 的页面。
当发生缺页时，算法首先检查表针指向的页面，如果R位是0就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置。(环形链表以逆时针方向增加)

如果R位是1就把R位清除并把表针前移一个位置(相当于清零R位并重新放入表中)。重复并直到找到R位为0为止。

### 3.4.6 最近最少使用页面置换算法
**Least Recent Used - LRU**
需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。需要每次访问内存都必须要更新整个链表。

`使用双向链表，并使用Map记录链表中每一位对应的页面，方便直接访问。`

### 3.4.7 用软件模拟LRU
**Not Frequentyly Used - NFU**
该算法将每个页面与一个软件计数器相关联，计数器的初始值为0。每次时钟中断时，由操作系统扫描内存中所有的页面，将每个页面的R位加到计数器上。这个计数器大体上跟踪了各个页面被访问的频繁程度。发生缺页中断时，则置换计数器值最小的页面。

`NFU的问题是在多次扫描中其第一次扫描中被频繁使用的页面会被带入第二次扫描中，其计数器的值仍然会很高。`

**老化(aging)算法**
在R位被加进之前先将计数器右移一位；其次，将R位加到计数器最左端的位而不是最右端的位。

发生缺页中断时，将置换计数器值最小的页面。如果一个页面在前面4个时钟滴答中都没有访问过，那么它的计数器最前面应该有4个连续的0.

与LRU的区别：
+ 在相同时钟滴答的范围内，如法得知两个页面被访问的次序。只能根据之前被访问的情况来选择置换的页面
+ 老化算法只有有限位数。如果有效位超出了有限位数，那么只能随机被之换掉


### 3.4.8 工作集页面置换算法
在单纯的分页系统中，刚启动进程时，在内存中并没有页面。在CPU试图取第一条指令时就会产生一次缺页中断，使操作系统装入含有第一条指令的页面。其他由访问全局数据和堆栈引起的缺页中断通常会紧接着发生。一段时间后，进程需要的大部分页面都已经在内存了，进程开始在较少缺页中断的情况下运行。这个策略称为**请求调页(demand paging)**，因为页面时在需要时被调入的，而不是预先装入。

**一个进程当前正在使用的页面的集合称为它的工作集。**

不少分页系统会设法跟踪进程的工作集，以确保在让进程运行以前，它的工作集就已在内存中。这个方法称为工作集模型，其目的在于大大减少缺页中断率。在进程运行前由预先装入其工作集页面也称为**预先调页(prepaging)。**

在任意时刻t，都存在一个集合，包含所有最近k次内存访问所访问过的页面。这个集合w(k,t)就是工作集。

**基于工作集的页面置换算法：**
思路是找出一个不在工作集中的页面并淘汰。这里的工作集为**过去的t秒实际运行时间中它所访问过的页面的集合。**

页表中除了其他域之外添加了一个上次使用该页面的近似时间。

在发生缺页中断时，扫描页表。首先检查表项的R位。如果**R位是1**，就把当前实际时间写进页表项的“上次使用时间”，以表示缺页中断发生时该页面正在被使用。既然该页面在当前时钟滴答内正在被使用，那就不应该被删除。

**如果R是0**，那么表示在当前时钟滴答中，这个页面还没有被访问过。首先计算其生存时间，生存时间等于当前实际时间减去上次使用时间。如果生存时间大于t秒这个界限，那么证明页面不在工作集中，并用新的页面来置换它。如果生存时间小于等于t，那么就要将这个页面临时保护起来，但是要记录生存时间最长的页面。如果扫面完整个页表却没有找到合适被淘汰的页面，也就意味着所有的页面都在工作集中。这种情况下，如果有一个或者多个R=0的页面，那么就淘汰生存时间最长的那一个。最坏情况下，所有的页面都被访问过，即R=1，那么随机选择一个页面淘汰，最好选择没有被修改过的，即“干净的”。

### 3.4.9 工作集时钟页面置换算法

当缺页中断发生后，需要扫描整个页表才能确定被淘汰的页面，因此基本工作集算法是比较费时的。
**WSClock(工作集时钟)算法** 基于时钟算法，并且使用了工作集信息。由于简单并且性能好，在实际工作中得到了广泛的应用。

![WSClock](https://res.cloudinary.com/harlan9613/image/upload/v1586155802/IMG/3-20_aewqpp.png)

数据结构：以页框为元素的循环表。
每次缺页时，首先检查指针指向的页面。如果R位置为1，该页面在当前时钟滴答中就被使用过，那么该页面就不适合被淘汰。然后把该页面的R位设置为0，指针指向下一个页面，并重复该算法。

如果页面R=0。生存时间大于t并且该页面是干净的，那么它就不在工作集中，并且磁盘上有一个有效的副本。申请此页框，并把新页面放在其中。如果**此页面被修改过**，为了避免由于调度写磁盘操作引起的进程切换，指针继续向前走，算法继续对下一个页面进行操作。**毕竟，有可能存在一个旧的且干净的页面可以立即使用。**

### 3.4.10 页面置换算法小结

|算法|注释|
|---|---|
|最优算法|不可实现，但可用作基准|
|NRU(最近未使用)算法|LRU的很粗糙的近似|
|FIFO(先进先出)算法|可能抛弃重要页面|
|第二次机会算法|比FIFO有较大的改善|
|时钟算法|现实的|
|LRU(最近最少使用)算法|很优秀，但很难实现|
|NFU(最近不常使用)算法|LRU的相对粗略的近似|
|老化算法|非常近似LRU的有效算法|
|工作集算法|实现起来开销很大|
|工作集时钟算法|好的有效算法|

最好的两种算法是**老化算法**和**工作集时钟算法**，它们分别基于LRU和工作集。它们都具有良好的页面调度性能，可以有效地实现。

## 3.5 分页系统中的设计问题
### 3.5.1 局部分配策略与全局分配策略

在多个进程运行的系统中，怎样在互相竞争的可运行进程之间分配内存：
+ 局部分配：在寻找最少使用的页面时只考虑相同进程内的页面
+ 全局分配：在运行的进程间动态地分配页框，寻找全局最少使用的页面。因此分配给每个进程的页数是随时间变化的

管理内存动态分配的一种方法是使用**PFF(Page Fault Frequency)** 算法。它指出了何时增加或减少分配给一个进程的页面。它仅仅控制分配集的大小。

### 3.5.2 负载控制
一旦所有进程的组合工作集超出了内存容量，就可能发生颠簸。
**一些进程需要更多的内存，但没有进程需要更少的内存。**

在决定交换出哪个进程时不光要考虑进程的大小和分页率，还要考虑它的特性(究竟是CPU密集型还是I/O密集型)已经其他进程的特性。

### 3.5.3 页面大小
大尺寸页面比小尺寸页面浪费了更多的内存。
小页面可以充分地利用TLB空间。

为了进行必要的平衡，操作系统有时会为系统中的不同部分使用不同的页面大小。

现在常见的页面的大小是**4KB和8KB。**

### 3.5.4 分离的指令空间和数据空间
为指令(程序空间)和数据设置分离的地址空间，分别为**I空间**和**D空间**。

### 3.5.5 共享页面
`几个不同的用户同时运行同一个程序是大型多道程序设计系统中常见的。`
不是所有页面都适合共享。特别的，那些只读的页面可以共享，但是数据页面则不能共享。

**写时复制：** 在进程对页面进行更新时，会生成一个该页的副本，这样每个进程都有自己的专用副本。两个复制都是可以读写的，对任何一个副本的操作都不会引发陷阱。

### 3.5.6 共享库
**共享库：DLL或动态链接库**
当一个共享库被装载和使用时，整个库并不是被一次性地读入内存。而是根据需要，以页面为单位装载的。因此没有被调用到的函数是不会被装载到内存中。

### 3.5.7 内存映射文件
进程可以通过发起一个系统调用，将一个文件映射到其虚拟地址空间的一部分

### 3.5.8 清除策略
**分页守护进程：** 大多数时间睡眠，但定期被唤醒以检查内存的状态。如果空间页框过少，分页守护进程通过预定的页面置换算法选择页面换出内存。分页守护进程保证了所有的空间页框是“干净”的，所以空间页框在被分配时不必再着急写回磁盘。

### 3.5.9 虚拟内存接口
共享内存：通过让一个进程把一片内存区域的名称通知另一个进程，而使得第二个进程可以把这片区域映射到它的虚拟地址空间中去。

## 3.6 有关实现的问题
### 3.6.1 与分页有关的工作
操作系统要在下面的四段时间里做与分页相关的工作：进程创建时，进程执行时，缺页中断时和进程终止时。

**进程创建时：** OS在内存中为页表分配空间并对其初始化。操作系统要在磁盘交换区中分配空间，以便在进程换出时在磁盘上有放置此进程的空间。操作系统用程序正文和数据对交换区进行初始化。把有关页表和磁盘交换区的信息存储在进程表中。

**进程执行时：** 重置MMU，刷新TLB，清除以前的进程遗留的痕迹。新进程的页表必须成为当前页表。

**缺页中断时：** 当缺页中断发生时，操作系统必须通过读硬件寄存器来确定哪个虚拟地址造成了缺页中断。

**进程退出时：** 操作系统必须释放进程的页表、页面和页面在硬盘上所占用的空间。

### 3.6.2 缺页中断处理
+ 硬件陷入内核，在栈堆中保存程序计数器
+ 启动汇编代码历程保存通用寄存器和其他信息
+ 操作系统尝试发现需要哪个虚拟页面
+ 操作系统检查发生缺页中断的虚拟地址是否有效，并检查是否有空闲页框
+ 如果页框脏了，那么写回磁盘
+ 页框干净后，操作系统查找需要的页面在磁盘上的地址
+ 当磁盘中断时，表明该页被装入
+ 恢复发生缺页中断指令前的状态
+ 调度引发缺页中断的进程
+ 恢复寄存器和其他状态信息

### 3.6.3 指令备份
引起缺页中断的指令会停止并引发操作系统的陷阱。在取出所需的页面后，需要重新启动引起陷阱的指令。

1. 对于占用多个连续地址的指令，操作系统有时无法准确的判断指令时从哪开始发生缺页中断
2. 有些硬件体系寻址方式采用自动增量，意味着执行指令的副作用是会增加一个或多个寄存器

**解决方法：** 通过一个隐藏的内部寄存器。在每条指令执行前，把程序计数器的内容复制到该寄存器。

### 3.6.4 锁定内存中的页面
设想一个进程通过系统调用从文件或其他设备中读取数据到其地址空间中的缓冲区。在等待I/O完成时，该进程被挂起，另一个进程被允许进行，而这个进程产生一个缺页中断。

`如果分页算法是全局算法，包含I/O缓冲区的页面会有很小的机会被选中换出，那么部分数据会被写入到最新装入的页面中`

**解决方法：** 锁住正在做I/O操作的内存中的页面以保证它不会被移除内存。锁住一个页面通常称为在内存中钉住(pinning)页面。
另一种方法是在内核缓冲区中完成所有的I/O操作，然后再将数据复制到用户页面。

### 3.6.5 后备存储
页面被换出时会存放在磁盘上的哪个位置：
最简单的情况下，当第一个进程启动时，在磁盘上留出与这个进程一样大的交换区块，剩余的为总空间减去这个交换分区。
另一种情况是事先什么也不分配，在页面换出时为其分配磁盘空间，并在换入时收回磁盘空间，这样内存中的进程不必固定于任何交换空间。这样，每一个进程都有一张表，记录页面在磁盘上的位置。

### 3.6.6 策略和机制的分离
存储管理系统被分为三个部分：
1. 一个底层MMU处理程序
2. 一个作为内核一部分的缺页中断处理程序
3. 一个运行在用户空间中的外部页面调度程序

## 3.7 分段
到目前为止，讨论的虚拟内存都是一维的，虚拟地址从0到最大地址，一个地址接着一个地址。**对许多问题来说，有两个或多个独立的地址空间可能比只有一个要好得多。**

比如一个编译器在编译的过程中会产生不同的表来记录不同的数据，比如符号表，语法分析树。如果将所有的表放在一个一维的虚拟内存地址中，有的表会随着编译的过程逐渐增大。那么会出现有表已经被占满，而有的表还存在着大量的空闲空间。

一个直观的方法就是提供多个互相独立的地址空间 - **段(segment)**。
段有着独立的地址空间，所以段与段之间互不影响。并且段中包含的数据可以动态的改变。

要在分段表示的存储器中指示一个地址需要两部分：1.段号，2.段内的地址

**分段的优点：**
1. 简化对经常变动的数据结构的管理
2. 每个过程都位于一个独立的段且起始地址为0，这样方便寻址
3. 每个过程被修改后其他过程不需要进行修改，因为不会出现使用空间上的冲突
4. 分段有助于进程之间共享过程和数据
5. 不同的段可以有不同的保护

##### 分页和分段的对比
|考察点|分页|分段
|---|---|---|
|需要程序员了解正在使用这种技术吗？|否|是|
|存在多少线性地址空间|1|许多|
|整个地址空间可以超出物理存储器的大小吗？|是|是|
|过程和数据可以被区分并分别被保护吗？|否|是|
|其大小浮动的表可以很容易提供吗|否|是|
|用户间过程的共享方便吗？|否|是|
|为什么发明这种技术？|为了得到大的线性地址空间而不必购买更大的物理存储器|为了使程序和数据可以被划分为逻辑上独立的地址空间且有助于共享和保护|

**程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护**

### 3.7.1 纯分段的实现
分段和分页的本质上是不同的：**页面的长度是固定的而分段不是。**

纯分段：在系统运行一段时间后内存会被分成多个**分段区**以及**空闲区**，这种现象被称为**棋盘形碎片**或**外部碎片(external fragmentation)**。这些空闲区可以使用内存紧缩来生成一大块空闲区。

### 3.7.2 分段和分页结合：MULTICS
对段进行分页，每个段都相当于一个虚拟地址空间。这样段中有需要的分页会被调入内存中。

结合了分段和分页的优点：统一的页面大小和只在使用段的一部分时不用把它全部调入内存，易于编程，模块化，保护和共享。

算法：
1. 根据段号找到段描述符
2. 检查该段的页表是否在内存中
3. 检查虚拟页面的页表项，如果不在内存中产生缺页中断
4. 把偏移量加到起始地址上
5. 进行读写操作

MULTICS硬件包含了16个字的高速TLB，对给定的关键字能并行搜索所有的表项。

### 3.7.3 分段和分页结合：Intel x86
Intel x86提供较小的段数(16K)，但是每个段可容纳大量的字数

x86的核心是两张表：**LDT(Local Descriptor Table，局部描述符表)** 和 **GDT(Global Descriptor Table, 全局描述符表)**。每个程序都有自己的LDT，但是同一台计算机上的所有程序共享一个GDT。


## 3.8 有关内存的研究

## 3.9 小结
简单的操作系统中是没有任何交换和分页的。程序装入内存，它将持续在内存中运行，直到结束。

交换技术实现了系统可以同时运行总内存占用超过实际物理内存大小的多个进程。

现代计算机都有某种形式的虚拟内存，每一个进程的地址空间被划分为同样大小的块，称为页面，页面可以被放入内存中任何可用的页框内。有很多页面置换算法，其中比较好的是老化算法和工作集时钟算法。

为了使分页系统工作良好，仅选择算法是不够的，还要关注诸多问题，例如工作集的确定，内存分配策略以及所需页面大小等。

如果要处理在执行过程中大小有变化的数据结构，分段是一个有用的选择，它还能简化共链接和共享。

## 习题
**1.** (1) 4bit一次只能提供 16 个进程同时在内存中使用。 (2) 需要特殊硬件的支持，因为这个比较过程需要快速

**2.** 这是个巧合。在这个例子中，先被存入内存中的进程大小为16384，所以第二个进程的基址寄存器的值就是16384。同时第二个进程的大小也为16384，所以其界限寄存器的大小就是16384。

**3.** 进行紧缩空间需要把字先读出来，然后再写到指定地点。32位长的字需要4ns，也就是 4byte 需要 8ns来读写。4GB总共是有 4 * 1024 * 1024 * 1024 个字节。那么总共需要的时间就是 8 * 1024 * 1024 * 1024 ns。

**4.** 
  + 首次适配算法：找到第一个合适的空闲区 -> 20MB, 10MB, 18MB
   + 最佳适配算法：找到最小的合适的空闲区 -> 12MB, 10MB, 9MB
   + 最差适配算法: 找到最大的合适的空闲区 -> 20MB, 18MB, 15MB
   + 下次适配算法: 记录上一次适配后的位置 -> 20MB, 18MB, 9MB
 
**5.** 物理地址是计算机硬件地址，这个地址是CPU进行读写的地址。虚拟地址是一个地址的抽象，每一个进程都有自己的虚拟地址，进程在虚拟地址上是连续的。CPU通过MMU将进程的虚拟地址映射到物理地址上。

**6.**  
   + 4KB = 4 * 1024 = 2^2 * 2^10 = 2^12，所以4KB页面每一页的范围是4096。
      + 20000，页号：4，偏移量：3616
      + 32768，页号：8，偏移量：0
      + 60000，页号：14，偏移量：2656
   + 8KB = 8 * 1024 = 2^3 * 2^10 = 2^13，所以8KB页面每一页的范围是8192。
      + 20000，页号：2，偏移量：3616
      + 32768，页号：4，偏移量：0
      + 60000，页号：7，偏移量：265

**7.**
   + 0K-4K 虚拟页面对应 8K-12K 物理页框，所以 20 对应物理地址为 8212
   + 4K-8K 虚拟页面对应 4K-8K 物理页框，所以 4100 对应物理地址为 4100
   + 8K-12K 虚拟页面对应 24K-28K 物理页框，所以 8300 对应物理地址为 24684

**8.** MMU是一块物理硬件，在CPU内，作用用于将虚拟内存映射到物理内存上。如果没有MMU单元且未对CPU做任何改动，那么可以在计算机内添加一块新的芯片用来支持虚拟内存到物理内存的映射。

**9.** 需要MMU单元来提供虚拟内存到物理内存的映射。同时，当缺页中断发生时需要让操作系统陷入陷阱。

**10.** 写时复制：在fork被调用后，父进程和子进程要共享程序文本和数据。对于分页系统来说，让所有进程分别拥有自己的页表，但是都指向同一个页面集合，每个进程的页表都是只读的。只有当其中一个进程试图修改页表时，才会生成该页的一个副本为这个进程所用。如果进程不修改页表则不会获得专属的页面副本。写时复制只会为需要修改页面的进程复制页面，所以减少了复制而提高了性能。如果手机系统支持页面共享和多道程序处理，那么需要支持写时复制。

**11.** TLB失效：虚拟页号不在TLB中会产生TLB失效。在TLB中删除一个页项，之后载入一个新的页项并执行失效的命令。如果在之后又访问了当前页面，则不会引起TLB失效。
+ (a) 如果一个页面的大小为4KB，那么每一个页面的范围就是4096。如果要使得每次的内层循环都引起TLB失效，则需要每次访问之前没有访问过的页面，所以这里 M 的值要至少为4096。N 的值只能确定循环的次数所以并不会影响TLB失效。
+ (b) 如果循环多遍的话，M 的值应该还是4096以保证每一次访问都能够访问到新页面。因为是多次循环，所以要确保 N 的值大于64K以此来破坏TLB，那么 X 的大小应当大于 64 * 4KB = 256KB。

**12.** 最坏情况下磁盘空间需求为：n * v - r。所有进程都在运行时需要的字节数为 n * v，有 r 字节的是存储在内存中的。这个值比真实的值要大很多，因为不会有 n 个进程在同时运行，而进程结束后占用的空间也会被释放掉。

**13.** 每执行 K 条命令会产生一次页面中断，每次中断执行额外的时间是 Nns，那么一此命令产生中断的消耗为 N/K。则一条命令的有效时间为 1 + N/K。

**14.** 32位地址空间总共有 2^32 个地址，8KB页面是 2^13 个地址，那么总共需要的页表就是 2^32 / 2^13 = 524288。因为每一个表项为一个32位的字，且每个字的装入时间是100ns，那么进程所需要的总时间就是 52428800ns = 52.428ms。因为总的运行时间是100ms，所以装入页表的CPU时间比例为 52.428%。

**15.** 
+ (a) 页面大小为 4KB = 2^12，虚拟地址的位数为 48，那么所有地址需要的页面数为 2^48 / 2^12 = 2^36。(参考答案应该有错)。
+ (b) TLB有32个表项，且一个指令可以放入一个页，功能是读取长整型元素。长整型元素的大小是 4B，那么一个页面所含有的长整数为 4KB / 4B = 1024 个。所以每读取1024个长整型元素就会引起一次TLB失效，并有一次内存访问来加载新页面。

**16.** TLB处理的页面访问占99%，能够在 1ns访问。页表项处理的页面访问就是1%，而0.01%的页面访问会发生缺页中断，占用 6ms 时钟周期，有效的访问就是0.99%，使用 1ns 时钟周期。所以能够得到 0.99 * 1 + 0.0099 * 100 + 0.0001 * 6 * 10^6 = 602 clock cycles 

**17.**
+ 多级页表可以减少需要的页面数量。
+ 页面大小是 16KB = 2^4 * 2^10，所以偏移量就是 14 位。那么我们剩下 38 - 14 = 24 位用来表示页表项。每一个页表项是 4B，所以 2^24 / 4 = 2^12。所以需要 12 位来索引页表，那么就剩下 12 位对应二级表项域。

**18.** 虽然页表项扩展到了64位，但是虚拟内存的总位数还是 32 位，那么只能够对 4GB 的内存进行寻址。 

**19.** 32 - 9 - 11 = 12，所以偏移量是 12 位。那么 2 ^ 12 = 2 ^ 2 * 2 ^ 10 = 4KB，页面大小为4KB，总共有 2^32 / 2^12 = 2^20 个页面。

**20.** 一级分页：需要 2^20个表项。如果是二级分页，且每部分有 10 位，那么一级分页有 1024 个表项。每一个一级分页的表项又指向 1024 个二级分页。因为程序和数据位于底层页面，而栈位于高层页面，所以总共需要底层，高层和其他共三个表项。

**21.** 页面大小为512B，程序起始地址为1020，栈指针在8192，每个指令占4B。<br/>
**LOAD 6144, R0**：指令在1020，1020位于第二个页面(512-1023)，所以指令页面是 **1**。6144 / 512 = 12，所以数据在页面 **12**。<br/>
**PUSH R0**：因为每个指令是4B，所以这个指令在1024，位于第三个页面(1024-1535)，所以指令页面是 **2**。8192 / 512 = 16，因为栈是向下增长，所以数据页面在 **15**。<br/>
**CALL 5120**：指令在1028，位于指令页面 **2**。数据页面仍在 **15**。<br/>
**JEQ 5152**：5152 / 512 > 10。所以数据页面在 **10**。

**22.** 命中开销是1ns，未命中开销是5ns，那么可以得到 hitRate * 1 + 5(1 - hitRate) = 2。求得 hitRate = 0.75。

**23.** 相连储存器将键与多个寄存器存储的内容同时进行比较。每一个寄存器都要有多个比较器来对比键与存储内容的每一位。所需要的晶体管的数量是寄存器数量的线性函数，所以这种扩展设计将会变得十分昂贵。

**24.** 页面大小是 8KB = 2^13。48位地址是 2^48。那么页表中的表项数量为 2^48 / 2^13 = 2^35 个。

**25.** 页面总数为 2^28 / 2^13 = 2^15 个。那么如果散列表的大小为 2^15，则平均散列度为 1，如果要小于 1，则散列表的大小至少为 2^16 = 32KB。

**26.** 如果编译器收集代码所在的位置，那么在链接的时候会利用这个信息来讲代码重新排列，以便程序位于调用得指令附近。

**27.** (a) 如果工作负载比该序列短，那么每次访问都会造成缺页中断，因为每一次访问的页面都不会在页框中，之前保存的页面都会被之后的页面所之换掉。除非页框的数量大于等于序列的长度，这里是512。(2) 如果分配了500个页框，那么只保留一个页框用于置换，这样0-498的页框都是固定的，这样可以省去这些页框中页面被置换掉的开销。

**28.** 初始页框为空，那么页面0，1，7，2都会发生缺页中断。之后访问页面3，发生缺页中断，页框为1，7，2，3。页面2，7，1都不会发生缺页中断。随后访问页面0，替换掉1，变成7，2，3，0。最后一个页面3不会发生缺页中断。所以次数为**6** 次。如果使用LRU算法，那么0，1，7，2会发生页面中断。访问页面3，发生缺页中断，页框为3，2，7，1。之后访问页面2，7，1，页框变为2，7，1，3。随后访问页面0，将页面3置换出来，所以最后一次访问页面3也会有缺页中断。缺页中断次数为**7**。

**29.** 第二次置换算法是如果访问页面的R位是1的话，将R位清零并换到链表的尾部。如果此时的R位分别是11011011。那么R位为1的B,C将会被置换到链表尾部，则被移走的页面是D。

**30.** 
| |页框0|页框1|页框2|页框3|
|---|---|---|---|---|
|时钟1：0111|00000000|10000000|10000000|10000000|
|时钟2：1011|10000000|01000000|11000000|11000000|
|时钟3：1010|11000000|00100000|11100000|01100000|
|时钟4：1101|11100000|10010000|01110000|10110000|
|时钟5：0010|01110000|01001000|10111000|01011000|
|时钟6：1010|10111000|00100100|11011100|00101100|
|时钟7：1100|11011100|10010010|01101110|00010110|
|时钟8：0001|01101110|01001001|00110111|10001011|

**31.** 0-1-2-1-2-0-3。LRU会替换页面1，Clock算法会替换页面0。 

**32.** 当前时间为2204，页面的上次使用时间为1213，那么页面的生存时间是 2204 - 1213 = 991。如果t=400，那么这个页面将会被移出。如果t=1000，因为生存时间小于间隔t，所以该页面在工作集中，不会被移出。

**33.** 
(a) 页面1：10，1，0，0。页面2：10，1，0，1
(b) 页面3：7，0，0，0。页面4：10，1，1，0

**34.** (a)置换最长时间未访问的页面。 (b)标注算法和替换算法。标注算法标注了每个页面的访问时间，替换算法将最长访问时间的标签置换出去。

**35.** 

**36.** (a) NRU将置换**页面2**，因为页面2的R位和M位都是0。(b) FIFO将置换**页面3**，因为页面3是最早载入的。(b) LRU将置换**页面1**，因为页面1是最近最早被访问的。(d)第二次置换算法将置换**页面2**，因为页面2是第一个R位为0的页面。

**37.** (a) B的页表会延迟更新当B不会去访问共享页面，或者访问时页面被置换掉了。这些情况都会导致B页表延迟更新，即便A页表在页面中断后将共享页面装入了内存。(b) 延迟页表更新会导致更多的缺页中断，这样会增加潜在的开销。

**38.** B段会有更少的缺页中断。因为每一个页框的大小为128个字，每一个整数占一个字，那么一个页框可以保存的数量就是数组中的两行。对于A段来说，按照列循环，因为一个页框最多能够保存两列，那么A段每遍历两个字就会触发一次页面中断，所以总次数是 64 * 64 / 2。对于B段来说，按照行循环，那么每个页框能够保存两行，所以B段每遍历128个字会触发一次页面中断，所以总次数是 64 / 2。

**39.** (a) 在终端服务器上开发分页系统。(b) 访问终端内存的时间要比访问磁盘的时间要快。但如果终端服务器宕机了的话会影响到所有共享页面的服务器。 

**40.** 这种换页磁鼓能够减少延迟。

**41.** 页面大小为 4KB = 4 * 1024 = 4096 Bytes。每个进程分配 65536 Bytes 的空间，那么每个进程的总页数为 65536 / 4096 = 16。正文段是 32768 Bytes，占用 8 个页面，数据段是 16386 Bytes，占用 5 个页面，堆栈有 15870 Bytes，占用 4 个页面。所以所需的页面大小为 17 > 16，因此页面大小为 4KB 时装不下这个进程。当页面大小为 512 Bytes时，总页面为 128。正文段占用 64 个，数据段占用 33 个，退栈占用 31 个，总数为 128，所以能够装下当前进程。

**42.** 运行60s发生15000次中断，那么每4ms就会发生一次缺页中断。处理中断需要2ms，那么缺页中断的间隔是2ms。如果内存加倍，那么中断间隔会变成原来的一半。所以发生一次中断需要的时间为 2ms + 1ms = 3ms。如果发生15000次中断需要的时间为 45s。

**43.** 适用于程序文本不会被修改，以及数据不会被修改。

**44.** 如果指令跨过了两个页面，那么提取指令会产生两个缺页中断。如果装入的字也跨过了两个页面，那么也会产生两个缺页中断。所以最差情况下会产生四次缺页中断。

**45.** 内部分段是由于最后一个分配单元没有被填满造成的。而外部分段是由于两个分配单元之间的空间被浪费造成的。分页系统使用的是内部分段，而纯分段系统使用的是外部分段。

**46.** TLB同时使用了段号和虚拟页号来查找，所以只需要使用一次查找。

**47.** 

**48.** 访问速度会更快。对于某些嵌入式系统来说，所调用的程序是固定的，且受控制的。那么直接使用物理内存能够提供更快的访问速度。

**49.** 
***
