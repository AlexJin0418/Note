# 第3章 内存管理
**分层存储体系 (memory hierarchy):**
+ 若干兆(MB)，快速，昂贵且易丢失的高速缓存(cache)
+ 数千兆(GB)，速度与价格适中且同样易丢失的内存(memory)
+ 几兆兆(TB)，低速，廉价，非易丢失的磁盘存储(disk)

**存储管理器 (memory manager):** 管理分层存储器体系。记录内存的使用情况，为进程分配和释放内存。

## 3.1 无存储器抽象
最简单的存储器抽象就是根本没有抽象，每一个程序都直接访问物理内存
`问题：1. 如果用户程序可以寻址内存的每一个字节，那么就可以很容易地破坏操作系统。2. 运行多个程序是很困难的。`

**在不使用存储器抽象的情况下运行多个程序**

**1. 交换概念：** 操作系统只需要把当前内存中所有内容保存到磁盘文件中，然后把下一个程序读入到内存中再运行即可。只要在某一个时间内内存中只有一个程序，那么就不会发生冲突

**2. 特殊硬件：** IBM 360早期模型使用一个存储在CPU特殊寄存器中的4位**保护键**，进程如果访问保护键与其程序状态字不同的内存，360的硬件会捕获这一事件。

`问题：两个程序都引用了绝对物理地址`
两个程序因为内存键不同会被装载到不同的内存地址，但是指令都是引用绝对物理地址，所以两个程序很可能会对相同的物理地址进行修改，导致程序崩溃。

**解决办法：** 使用**静态重定位**的技术修改后装载程序的地址，将程序起始的物理地址加到每一个程序地址上。但是运行程序需要提供额外的信息来区分哪些字是**常数**，哪些字是**可重定位地址**，并且重定位会减慢装载速度。

## 3.2 一种存储器抽象: 地址空间

### 3.2.1 地址空间的概念
保护键无法完美解决多个应用程序处于内存中互不影响的问题，一个更好的办法是创造一个新的存储器抽象：**地址空间**。
> **地址空间**是一个进程可用于寻址内存的一套地址集合。每一个进程都有一个自己的地址空间，并且这个地址空间独立于其他进程的地址空间。

**基址寄存器与界限寄存器：** 使用**动态重定位**，把每一个进程的地址空间映射到物理内存的不同部分。两个特殊的CPU硬件寄存器
+ 基址寄存器：装载程序的起始物理地址
+ 界限寄存器：装载程序的长度

在进程访问内存时，CPU硬件会首先将基址值加到进程发出的地址值上，同时检查程序提供的地址是否等于或大于界限寄存器中的值。

`缺点：每次访问内存都需要进行加法和比较的运算。加法运算由于进位传递的问题会显得很慢。`

### 3.2.2 交换技术
如果计算机的物理内存足够大，可以保存所有进程，那么之前所提及的方案或多或少都是可行的。但是很多程序开始处理数据之后可能需要数千兆的空间，所以把所有进程一直保存在内存中需要巨大的内存，如果内存不够大就会导致`内存超载`。

有两种方法处理内存超载：**交换(swapping)技术**，即把进程调用内存中运行一段时间后存回磁盘。另一种是**虚拟内存 (virtual memory)**，使程序在只有一部分被调入内存的情况下运行。

**内存紧缩 (memory compaction)：** 在交换内存的过程中产生了多个空闲区，通过把所有的进程尽可能向下移动，有可能将这些小的空闲区合成一大块。通常不进行这个操作，因为它要耗费大量的CPU时间。 

`问题：如果进程创建时其大小是固定的并且不会改变，则分配很简单。但如果进程需要在堆中动态地分配内存，那么进程空间增长时就面临获取更多空闲空间的问题。`
一种可行的方法是，当换入或移动进程时提前为它分配一些额外的内存供其堆栈段进行增长。

### 3.2.3 空闲内存管理
在动态分配内存时，操作系统必须对其进行管理。一般有**位图**和**空闲区链表**两种方法。

**1. 使用位图的存储管理**
> 使用位图方法时，内存可能被划分成小到几个字或大到几千字节的分配单元。每个分配单元对应于位图中的一位，0表示空闲，1表示占用（或者相反）。一块内存区和其对应的位图如图3-6所示。
![](https://img-blog.csdnimg.cn/20190414220059645.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxNDc1NzAzOTgw,size_16,color_FFFFFF,t_70)

内存的大小和分配单元的大小决定了位图的大小。这种方法的主要问题是：`在把一个占k个分配单元的进程调入内存时，存储管理器必须所搜位图，在位图中找出k个连续0的串。查找指定长度的连续0串是耗时操作，这时位图的缺点。`

**2. 使用链表的存储管理**
维护一个记录已分配内存段和空闲内存段的链表。其中链表中的一个结点或者包含一个进程，或者是两个进程间的一块空闲区。一个节点包括**空闲区: H** 或者 **进程: P** 的指示标志，**起始地址**，**长度**和**指向下一个节点**的指针。链表使用双向链表可能比单向链表更方便，更易于找到上一个节点。

当按照地址顺序在链表中存放进程和空闲区时，有几种算法可以用来为创建的进程(或从磁盘中换入的已存在的进程)分派内存。
+ **首次适配(first fit)算法:** 沿着段链表从头进行搜索，找到足够大的空闲区域。这种方法速度快。
+ **下次适配(next fit)算法:** 记录每次找到合适空闲区的位置，以便下次寻找空闲区时从上次结束的地方开始搜索。
+ **最佳适配(best fit)算法:** 搜索整个空闲区，找出能够容纳进程的最小空闲区。速度慢且会生成大量无用地小空闲空间。
+ **最差适配(worst fit)算法:** 总是分配最大地可用空闲区，使新的空闲区可以继续使用。
+ **快速适配(quick fit)算法:** 为常用大小的空闲区维护单独的链表。比如链表第一项是指向4kb大小的空闲区的指针，第二项是指向8kb大小的空闲区的指针。快速适配算法能够快速地查找**指定大小的**空闲区。`所有对链表排序的算法都有一个缺点：当一个进程终止或被换出时，寻找它的相邻块并查看是否可以合并的过程是非常费时的(？查看相邻块是否可以合并，如果合并需要重新排序)。如果不进行合并，那内存很快会分裂出大量进程无法使用的小空闲区。`

**对算法速度的优化：** 单独维护进程链表和空闲区链表。这样只用检查空闲区链表，提高算法速度。但会增加复杂度和内存释放速度变慢，因为要将进程链表地回收段删除并插入空闲的区链表。
**对最佳适配算法的优化：** 进程和空闲区使用不同链表，并对空闲区链表按照大小排序，那么最合适的空闲区段就是最小适配的。
**对空闲链表的优化：** 空闲区第一个字可以是空闲区大小，而第二个字可以是指向下一个空闲区的指针。

## 3.3 虚拟内存
计算机的发展导致运行的程序往往大到内存无法容纳，而且必然需要系统能够支持多个程序同时运行。
20世纪60年代的做法是将整个程序分割成许多片段，称为**覆盖(overlay)**。覆盖块存放在磁盘上，在需要时由操作系统动态地换入换出。问题在于程序员必须把程序分割成多个片段。把一个大程序分割成小的，模块化的片段是非常费时和枯燥的，并且易于出错。

**虚拟内存(virtual memory)：** 虚拟内存的基本思想是，每个程序拥有自己的地址空间，这个空间被分割成多个块，每一块称作一**页**或**页面(page)**。每一页有连续的地址范围。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行。

### 3.3.1 分页
由程序产生的这些地址成为**虚拟地址(virtual address)**，它们构成了一个**虚拟地址空间(virtual address space)**。
+ 没有虚拟内存的计算机上，系统直接将虚拟地址送到内存总线上，读写操作使用具有同样地址的物理内存字
+ 有虚拟内存的情况下，虚拟地址不是被直接送到内存总线上，而是被送到**内存管理单元(Memory Management Unit, MMU)**，MMU把虚拟地址映射为物理内存地址

虚拟地址空间按照固定大小划分为被称为**页面(page)**的若干单元。在物理内存中对应的单元成为**页框(page frame)**。页面和页框的大小是一样的。

当程序试图访问一个地址时，首先会将虚拟地址送到MMU。MMU看到虚拟地址后，根据其映射结果，将虚拟地址对应的物理地址送到内存总线上。内存对MMU一无所知，它只看到一个读或者写地址的请求并执行它。MMU有效地把虚拟地址映射到了物理地址上。

`但这并没有解决虚拟地址空间比物理内存大的问题。假设物理页框的数量为8，而虚拟页面的数量为16，那么只有8个虚拟页面能够被映射到物理地址上，而其他8个虚拟页面则没有被映射。`
在实际的硬件中，用一个**在/不在 (present / absent bit)位**记录页面在内存中的实际存在情况。

**如果程序访问了一个未被映射的页面，并执行指令时，将会发生什么情况？**
首先虚拟地址将会被送到MMU。MMU发现这个虚拟地址所在的虚拟页面没有物理页框的映射，于是使CPU陷入到系统操作。这个陷阱被成为**页面中断**或**页面错误(page fault)**。操作系统找到一个很少被使用的页框，并把它的内容写入磁盘。随后把需要访问的页面读到刚才回收的页框中，修改映射关系，然后重新启动引起陷阱的指令。

**MMU的工作机制：** 对于16位地址的计算机，其虚拟地址的范围是0到64K-1。假如虚拟页面的大小是4KB，那么总共就有16个虚拟页面。如果虚拟地址是8196，其对应的二进制为 0010000000000100。我们就可以将这个16位的虚拟地址分为4位的页号和12位的偏移量。4位的页号能够表示16个页面，而12位的偏移量可以为一页内的全部4096个字节编址。可用页号作为**页表(page table)** 的索引，以得出对应于该虚拟页面的页框号。如果“在/不在”位是0，则会引起一个操作系统陷阱。如果虚拟页面有对应的物理页面，那么将对应的页框号复制到寄存器的高3位中，同时加上虚拟地址中12位的偏移量。如此就构成了15位的物理地址。

### 3.3.2 页表
作为最简单的实现，虚拟地址到物理地址的映射可以概括为：虚拟地址被分成虚拟页号(高位部分)和偏移量(地位部分)两部分。对于虚拟地址的划分应对应不同的页面大小。

> 虚拟页号可以作页表的索引，以找到该虚拟页面对应的页表项。由页表项可以找到页框号。然后把页框号拼接到偏移量的高位端，以替换掉虚拟页号，形成送往内存的物理地址。简单来说，页表是一个函数，它的参数是虚拟页号，输出的结果是物理页框号。通过这个函数可以把虚拟地址中的虚拟页面替换成页框域，从而形成物理地址。

**页表项的结构**
![page_table](https://res.cloudinary.com/harlan9613/image/upload/v1585189393/IMG/Page_table_yoxc5z.jpg)
不同计算机的页表项大小可能不一样，但32位是一个常用的大小。最重要的是**页框号**。毕竟页映射的目的是找到这个值，其次是“在/不在”位。这一位是1时表示该表项是有效的，如果是0，表示对应的虚拟页面不在内存中，会引起一个缺页中断。

**保护(protectio)** 位指出一个页允许什么类型的访问。最简单的形式是这个域只有一位，0表示读/写，1表示只读。更先进的方法是使用三位，各位分别对应是否启用读，写，执行该页面。

**修改(modified)** 和**访问(referenced)**位，在写入一页时由硬件自动设置修改位。如果一个页面已经被修改过，则必须把它写回磁盘。如过一个页面没有被修改过，那么只需要简单地丢弃掉就可以了。这一位也被叫做**脏位(dirty)**。

访问位地值用来帮助操作系统在发生缺页中断时选择要被淘汰地页面。不再使用地页面要比正在使用地页面更适合淘汰。访问位在页面置换算法中起到很重要地作用。

### 3.3.3 加速分页过程
在任何分页系统中，都需要考虑两个主要的问题：
+ 虚拟地址到物理地址地映射必须非常快。
+ 如果虚拟地址空间很大，页表也会很大。

**1. 转换检测缓冲区 (Translation Lookaside Buffer, TLB)：** 是一个为计算机配备地小型硬件设备。将虚拟地址直接映射到物理地址，而不必再访问页表。这个设备通常在MMU中，包含少量地表项。每个表项记录了一个页面地相关信息，包括虚拟页号，页面的修改位，保护码(读，取，执行权限)和该页所对应地物理页框。
![TLB](https://res.cloudinary.com/harlan9613/image/upload/v1585192974/IMG/TLB_mle18e.jpg)

将虚拟地址放入MMU中进行转换时，硬件首先通过将该虚拟页号与TLB中所有表项同时进行匹配，判断该虚拟页面是否在其中。如果发现了一个有效的匹配并且要进行的访问操作并不违反保护位，则将页框号直接从TLB中取出而不必再访问页表。如果虚拟页号确实在TLB中，但指令试图在一个只读页面上进行写操作，则会产生一个错误保护。

如果MMU检测到虚拟页面没有在TLB中，就会进行正常的页表检查。**接着从TLB中淘汰掉一个表项，然后用新找到的页表项代替它**。这样，如果这一个虚拟页表被很快再次访问，第二次访问TLB时就会查询到对应的页框号。被淘汰的页表将修改位复制到内存中的页表项，而除了访问位，其他的值不变。当页表项从页表中装入TLB时。所有的值都来自内存。

**2. 软件TLB管理：**
对TLB的管理和TLB的失效处理都完全由MMU硬件来实现。

许多现在的机器，对页面管理是由软件实现的。TLB表被操作系统显式地装载。
当一个页面访问在内存中而不在TLB时，将产生**软失效(soft miss)**。那么此时要做的就是更新一下TLB。
当一个页面访问即不再内存，也不再TLB时，将产生**硬失效(hard miss)**。此可需要磁盘存取以装入该页面。


### 3.3.4 针对大内存的页表

**1. 多级页表：**
如果一个32位的虚拟地址被分为10位的PT1域，10位的PT2域和12位的Offset(偏移量)。因为偏移量是12位，所以页面大小是4KB，共有2^20个页面。
> 对于32位的CPU来说，能够寻到的最大地址范围为 2^32 个地址。每个地址访问一个Byte，那么地址范围就是 4294967296 Byte = 4GB。
12位的偏移量指的是能表示的数的范围是 [0] - [2^12 - 1]，那么这个范围就是 2^12 = 4K。一位对应一个字节，所以是4KB。
我们共有4GB范围的地址，每一个分页的范围是4KB，那么总共的页面数就是 4GB / 4KB = 2^20。
那么可以通过前20位来确定在 2^20 个页表中的哪一个页表，然后用12位的偏移来确定具体的位置。

引入多级页表的原因是避免把全部页表一直保存在内存中。特别是那些从不需要的页表就不应该保留。
![page_table2](https://res.cloudinary.com/harlan9613/image/upload/v1585196525/IMG/page_table2_osjooh.jpg)
上图中，左边是顶级页表，有1024个表项，对应于10位的PT1域。当一个虚拟地址被送到MMU时，MMU首先提取PT1域并把该值作为访问顶级页表的索引。因为**4GB** 的虚拟内存空间被分为了**1024** 个表项，那么每一个表项都表示一块**4MB** 的地址范围。

由索引顶级页表得到的表项中含有二级页表的地址或者页框号。**顶级页表的表项0指向程序正文的页表，表项1指向数据的页表，表项1023指向堆栈的页表，其他表项未用。** 现在把PT2域作为访问选定的二级页表的索引，以便找到该虚拟页面的对应页框号。

值得注意的是，虽然图中的虚拟地址超过100万个页面，实际上只需要四个页表：顶级页表，以及正文段，数据段和堆栈段的二级页表。

图中的二级页表可扩充位三级，四级或者多级。级数越多，灵活性就越大。

**2. 倒排页表**
倒排页表的设计中，实际内存中的每个页框对应一个表项。而不是虚拟页面对应一个表项。
`从虚拟地址到物理地址的转换会变得很困难，需要搜索整个倒排页表来查找某一个表项`
可以使用TLB来记录所有频繁使用的页面。

## 3.4 页面置换算法
当发生页面中断时，操作系统必须在内存中选择一个页面将其换出内存，以便为即将调入的页面腾出空间。
+ 如果换出的页面在内存驻留期间已经被修改过，就必须把它写回磁盘以更新该页面在磁盘上的副本
+ 如果该页面没有被修改过，那么不需要写回磁盘。直接调用页面覆盖被淘汰的页面就可以

### 3.4.1 最优界面置换算法
在缺页中断发生时，有些页面在内存中。每个页面都可以用在该页面首次被访问前索要执行的指令数作为标记。
最优置换算法规定应该置换**标记最大的页面**。
`问题是无法实现的。因为操作系统无法知道各个页面下一次将在什么时候被访问。`

### 3.4.2 最近未使用页面置换算法
**Not Recently Used - NRU**
使用访问位和修改位来构造一个简单的页面置换算法：当启动一个进程时，它的所有页面的两个位都由操作系统设置为0，访问位被定期地清零，以区别最近没有被访问地页面和被访问地页面。
当发生缺页中断时，操作系统检查所有的页面并根据它们地R位和M位地值，把它们分成4类：
+ 第0类：没有被访问，没有被修改
+ 第1类：没有被访问，已被修改
+ 第2类：已被访问，没有被修改
+ 第3类：已被访问，已被修改

因为时钟会不断地将R位清零，所以第2类会变成第0类。不清除修改位是因为在淘汰页面时需要这个信息来判断这个页是否需要从内存写回磁盘记录信息还是直接被覆盖淘汰。

**NRU**算法随机地从类编号最小地非空类中挑选一个页面淘汰。

### 3.4.3 先进先出页面置换算法
**First-in First-out FIFO**
操作系统维护一个所有**当前在内存中地页面**的链表，最新进入的页面放在表尾，最早进入的在表头。发生缺页中断时，淘汰表头的页面并吧新调入的页面加到表尾。
`有可能会淘汰掉常用的页表`

### 3.4.4 第二次机会页面置换算法
对FIFO进行一个修改。判断最早放入链表的页面的R位是不是0，如果是0，那么可以直接被置换掉。如果是1，则将R位清零，并把这个页面重新插入链表，**修改它装入的时间为最新的时间。**

该算法就是寻找一个在最近的时钟间隔内没有被访问过的页面。如果所有的页面都被访问过了，该算法就简化为纯粹的FIFO算法。

### 3.4.5 时钟页面置换算法
把所有的页面保存在一个类似钟面的环形链表中，一个表针指向**最老** 的页面。
当发生缺页时，算法首先检查表针指向的页面，如果R位是0就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置。(环形链表以逆时针方向增加)

如果R位是1就把R位清除并把表针前移一个位置(相当于清零R位并重新放入表中)。重复并直到找到R位为0为止。

### 3.4.6 最近最少使用页面置换算法
**Least Recent Used - LRU**
需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。需要每次访问内存都必须要更新整个链表。

`使用双向链表，并使用Map记录链表中每一位对应的页面，方便直接访问。`

### 3.4.7 用软件模拟LRU
**Not Frequentyly Used - NFU**
该算法将每个页面与一个软件计数器相关联，计数器的初始值为0。每次时钟中断时，由操作系统扫描内存中所有的页面，将每个页面的R位加到计数器上。这个计数器大体上跟踪了各个页面被访问的频繁程度。发生缺页中断时，则置换计数器值最小的页面。

`NFU的问题是在多次扫描中其第一次扫描中被频繁使用的页面会被带入第二次扫描中，其计数器的值仍然会很高。`

**老化(aging)算法**
在R位被加进之前先将计数器右移一位；其次，将R位加到计数器最左端的位而不是最右端的位。

发生缺页中断时，将置换计数器值最小的页面。如果一个页面在前面4个时钟滴答中都没有访问过，那么它的计数器最前面应该有4个连续的0.

与LRU的区别：
+ 在相同时钟滴答的范围内，如法得知两个页面被访问的次序。只能根据之前被访问的情况来选择置换的页面
+ 老化算法只有有限位数。如果有效位超出了有限位数，那么只能随机被之换掉


### 3.4.8 工作集页面置换算法
在单纯的分页系统中，刚启动进程时，在内存中并没有页面。在CPU试图取第一条指令时就会产生一次缺页中断，使操作系统装入含有第一条指令的页面。其他由访问全局数据和堆栈引起的缺页中断通常会紧接着发生。一段时间后，进程需要的大部分页面都已经在内存了，进程开始在较少缺页中断的情况下运行。这个策略称为**请求调页(demand paging)**，因为页面时在需要时被调入的，而不是预先装入。

**一个进程当前正在使用的页面的集合称为它的工作集。**

不少分页系统会设法跟踪进程的工作集，以确保在让进程运行以前，它的工作集就已在内存中。这个方法称为工作集模型，其目的在于大大减少缺页中断率。在进程运行前由预先装入其工作集页面也称为**预先调页(prepaging)。**

在任意时刻t，都存在一个集合，包含所有最近k次内存访问所访问过的页面。这个集合w(k,t)就是工作集。

**基于工作集的页面置换算法：**
思路是找出一个不在工作集中的页面并淘汰。这里的工作集为**过去的t秒实际运行时间中它所访问过的页面的集合。**

页表中除了其他域之外添加了一个上次使用该页面的近似时间。

在发生缺页中断时，扫描页表。首先检查表项的R位。如果**R位是1**，就把当前实际时间写进页表项的“上次使用时间”，以表示缺页中断发生时该页面正在被使用。既然该页面在当前时钟滴答内正在被使用，那就不应该被删除。

**如果R是0**，那么表示在当前时钟滴答中，这个页面还没有被访问过。首先计算其生存时间，生存时间等于当前实际时间减去上次使用时间。如果生存时间大于t秒这个界限，那么证明页面不在工作集中，并用新的页面来置换它。如果生存时间小于等于t，那么就要将这个页面临时保护起来，但是要记录生存时间最长的页面。如果扫面完整个页表却没有找到合适被淘汰的页面，也就意味着所有的页面都在工作集中。这种情况下，如果有一个或者多个R=0的页面，那么就淘汰生存时间最长的那一个。最坏情况下，所有的页面都被访问过，即R=1，那么随机选择一个页面淘汰，最好选择没有被修改过的，即“干净的”。

### 3.4.9 工作集时钟页面置换算法

当缺页中断发生后，需要扫描整个页表才能确定被淘汰的页面，因此基本工作集算法是比较费时的。
**WSClock(工作集时钟)算法** 基于时钟算法，并且使用了工作集信息。由于简单并且性能好，在实际工作中得到了广泛的应用。

![WSClock](https://res.cloudinary.com/harlan9613/image/upload/v1585394640/IMG/WSClock_z7kupu.jpg)
数据结构：以页框为元素的循环表。
每次缺页时，首先检查指针指向的页面。如果R位置为1，该页面在当前时钟滴答中就被使用过，那么该页面就不适合被淘汰。然后把该页面的R位设置为0，指针指向下一个页面，并重复该算法。

如果页面R=0。生存时间大于t并且该页面是干净的，那么它就不在工作集中，并且磁盘上有一个有效的副本。申请此页框，并把新页面放在其中。如果**此页面被修改过**，为了避免由于调度写磁盘操作引起的进程切换，指针继续向前走，算法继续对下一个页面进行操作。**毕竟，有可能存在一个旧的且干净的页面可以立即使用。**

### 3.4.10 页面置换算法小结

|算法|注释|
|---|---|
|最优算法|不可实现，但可用作基准|
|NRU(最近未使用)算法|LRU的很粗糙的近似|
|FIFO(先进先出)算法|可能抛弃重要页面|
|第二次机会算法|比FIFO有较大的改善|
|时钟算法|现实的|
|LRU(最近最少使用)算法|很优秀，但很难实现|
|NFU(最近不常使用)算法|LRU的相对粗略的近似|
|老化算法|非常近似LRU的有效算法|
|工作集算法|实现起来开销很大|
|工作集时钟算法|好的有效算法|

最好的两种算法是**老化算法**和**工作集时钟算法**，它们分别基于LRU和工作集。它们都具有良好的页面调度性能，可以有效地实现。

## 3.5 分页系统中的设计问题
### 3.5.1 局部分配策略与全局分配策略

在多个进程运行的系统中，怎样在互相竞争的可运行进程之间分配内存：
+ 局部分配：在寻找最少使用的页面时只考虑相同进程内的页面
+ 全局分配：在运行的进程间动态地分配页框，寻找全局最少使用的页面。因此分配给每个进程的页数是随时间变化的

管理内存动态分配的一种方法是使用**PFF(Page Fault Frequency)** 算法。它指出了何时增加或减少分配给一个进程的页面。它仅仅控制分配集的大小。

### 3.5.2 负载控制
一旦所有进程的组合工作集超出了内存容量，就可能发生颠簸。
**一些进程需要更多的内存，但没有进程需要更少的内存。**

在决定交换出哪个进程时不光要考虑进程的大小和分页率，还要考虑它的特性(究竟是CPU密集型还是I/O密集型)已经其他进程的特性。

### 3.5.3 页面大小
大尺寸页面比小尺寸页面浪费了更多的内存。
小页面可以充分地利用TLB空间。

为了进行必要的平衡，操作系统有时会为系统中的不同部分使用不同的页面大小。

现在常见的页面的大小是**4KB和8KB。**

### 3.5.4 分离的指令空间和数据空间
为指令(程序空间)和数据设置分离的地址空间，分别为**I空间**和**D空间**。

### 3.5.5 共享页面
`几个不同的用户同时运行同一个程序是大型多道程序设计系统中常见的。`
不是所有页面都适合共享。特别的，那些只读的页面可以共享，但是数据页面则不能共享。

**写时复制：** 在进程对页面进行更新时，会生成一个该页的副本，这样每个进程都有自己的专用副本。两个复制都是可以读写的，对任何一个副本的操作都不会引发陷阱。

### 3.5.6 共享库
**共享库：DLL或动态链接库**
当一个共享库被装载和使用时，整个库并不是被一次性地读入内存。而是根据需要，以页面为单位装载的。因此没有被调用到的函数是不会被装载到内存中。

### 3.5.7 内存映射文件
进程可以通过发起一个系统调用，将一个文件映射到其虚拟地址空间的一部分

### 3.5.8 清除策略
**分页守护进程：** 大多数时间睡眠，但定期被唤醒以检查内存的状态。如果空间页框过少，分页守护进程通过预定的页面置换算法选择页面换出内存。分页守护进程保证了所有的空间页框是“干净”的，所以空间页框在被分配时不必再着急写回磁盘。

### 3.5.9 虚拟内存接口
共享内存：通过让一个进程把一片内存区域的名称通知另一个进程，而使得第二个进程可以把这片区域映射到它的虚拟地址空间中去。

## 3.6 有关实现的问题
### 3.6.1 与分页有关的工作
操作系统要在下面的四段时间里做与分页相关的工作：进程创建时，进程执行时，缺页中断时和进程终止时。

**进程创建时：** OS在内存中为页表分配空间并对其初始化。操作系统要在磁盘交换区中分配空间，以便在进程换出时在磁盘上有放置此进程的空间。操作系统用程序正文和数据对交换区进行初始化。把有关页表和磁盘交换区的信息存储在进程表中。

**进程执行时：** 重置MMU，刷新TLB，清除以前的进程遗留的痕迹。新进程的页表必须成为当前页表。

**缺页中断时：** 当缺页中断发生时，操作系统必须通过读硬件寄存器来确定哪个虚拟地址造成了缺页中断。

**进程退出时：** 操作系统必须释放进程的页表、页面和页面在硬盘上所占用的空间。

### 3.6.2 缺页中断处理
+ 硬件陷入内核，在栈堆中保存程序计数器
+ 启动汇编代码历程保存通用寄存器和其他信息
+ 操作系统尝试发现需要哪个虚拟页面
+ 操作系统检查发生缺页中断的虚拟地址是否有效，并检查是否有空闲页框
+ 如果页框脏了，那么写回磁盘
+ 页框干净后，操作系统查找需要的页面在磁盘上的地址
+ 当磁盘中断时，表明该页被装入
+ 恢复发生缺页中断指令前的状态
+ 调度引发缺页中断的进程
+ 恢复寄存器和其他状态信息

### 3.6.3 指令备份
引起缺页中断的指令会停止并引发操作系统的陷阱。在取出所需的页面后，需要重新启动引起陷阱的指令。

1. 对于占用多个连续地址的指令，操作系统有时无法准确的判断指令时从哪开始发生缺页中断
2. 有些硬件体系寻址方式采用自动增量，意味着执行指令的副作用是会增加一个或多个寄存器

**解决方法：** 通过一个隐藏的内部寄存器。在每条指令执行前，把程序计数器的内容复制到该寄存器。

### 3.6.4 锁定内存中的页面
设想一个进程通过系统调用从文件或其他设备中读取数据到其地址空间中的缓冲区。在等待I/O完成时，该进程被挂起，另一个进程被允许进行，而这个进程产生一个缺页中断。

`如果分页算法是全局算法，包含I/O缓冲区的页面会有很小的机会被选中换出，那么部分数据会被写入到最新装入的页面中`

**解决方法：** 锁住正在做I/O操作的内存中的页面以保证它不会被移除内存。锁住一个页面通常称为在内存中钉住(pinning)页面。
另一种方法是在内核缓冲区中完成所有的I/O操作，然后再将数据复制到用户页面。

### 3.6.5 后备存储
页面被换出时会存放在磁盘上的哪个位置：
最简单的情况下，当第一个进程启动时，在磁盘上留出与这个进程一样大的交换区块，剩余的为总空间减去这个交换分区。
另一种情况是事先什么也不分配，在页面换出时为其分配磁盘空间，并在换入时收回磁盘空间，这样内存中的进程不必固定于任何交换空间。这样，每一个进程都有一张表，记录页面在磁盘上的位置。

### 3.6.6 策略和机制的分离
存储管理系统被分为三个部分：
1. 一个底层MMU处理程序
2. 一个作为内核一部分的缺页中断处理程序
3. 一个运行在用户空间中的外部页面调度程序

## 3.7 分段
到目前为止，讨论的虚拟内存都是一维的，虚拟地址从0到最大地址，一个地址接着一个地址。**对许多问题来说，有两个或多个独立的地址空间可能比只有一个要好得多。**

比如一个编译器在编译的过程中会产生不同的表来记录不同的数据，比如符号表，语法分析树。如果将所有的表放在一个一维的虚拟内存地址中，有的表会随着编译的过程逐渐增大。那么会出现有表已经被占满，而有的表还存在着大量的空闲空间。

一个直观的方法就是提供多个互相独立的地址空间 - **段(segment)**。
段有着独立的地址空间，所以段与段之间互不影响。并且段中包含的数据可以动态的改变。

要在分段表示的存储器中指示一个地址需要两部分：1.段号，2.段内的地址

**分段的优点：**
1. 简化对经常变动的数据结构的管理
2. 每个过程都位于一个独立的段且起始地址为0，这样方便寻址
3. 每个过程被修改后其他过程不需要进行修改，因为不会出现使用空间上的冲突
4. 分段有助于进程之间共享过程和数据
5. 不同的段可以有不同的保护

##### 分页和分段的对比
|考察点|分页|分段
|---|---|---|
|需要程序员了解正在使用这种技术吗？|否|是|
|存在多少线性地址空间|1|许多|
|整个地址空间可以超出物理存储器的大小吗？|是|是|
|过程和数据可以被区分并分别被保护吗？|否|是|
|其大小浮动的表可以很容易提供吗|否|是|
|用户间过程的共享方便吗？|否|是|
|为什么发明这种技术？|为了得到大的线性地址空间而不必购买更大的物理存储器|为了使程序和数据可以被划分为逻辑上独立的地址空间且有助于共享和保护|

**程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护**

### 3.7.1 纯分段的实现
