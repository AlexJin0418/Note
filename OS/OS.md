# 内存管理
**分层存储体系 (memory hierarchy):**
+ 若干兆(MB)，快速，昂贵且易丢失的高速缓存(cache)
+ 数千兆(GB)，速度与价格适中且同样易丢失的内存(memory)
+ 几兆兆(TB)，低速，廉价，非易丢失的磁盘存储(disk)

**存储管理器 (memory manager):** 管理分层存储器体系。记录内存的使用情况，为进程分配和释放内存。

#### 3.1 无存储器抽象
最简单的存储器抽象就是根本没有抽象，每一个程序都直接访问物理内存
`问题：1. 如果用户程序可以寻址内存的每一个字节，那么就可以很容易地破坏操作系统。2. 运行多个程序是很困难的。`

**在不使用存储器抽象的情况下运行多个程序**

**1. 交换概念：** 操作系统只需要把当前内存中所有内容保存到磁盘文件中，然后把下一个程序读入到内存中再运行即可。只要在某一个时间内内存中只有一个程序，那么就不会发生冲突

**2. 特殊硬件：** IBM 360早期模型使用一个存储在CPU特殊寄存器中的4位**保护键**，进程如果访问保护键与其程序状态字不同的内存，360的硬件会捕获这一事件。

`问题：两个程序都引用了绝对物理地址`
两个程序因为内存键不同会被装载到不同的内存地址，但是指令都是引用绝对物理地址，所以两个程序很可能会对相同的物理地址进行修改，导致程序崩溃。

**解决办法：** 使用**静态重定位**的技术修改后装载程序的地址，将程序起始的物理地址加到每一个程序地址上。但是运行程序需要提供额外的信息来区分哪些字是**常数**，哪些字是**可重定位地址**，并且重定位会减慢装载速度。

#### 3.2 一种存储器抽象: 地址空间

##### 3.2.1 地址空间的概念
保护键无法完美解决多个应用程序处于内存中互不影响的问题，一个更好的办法是创造一个新的存储器抽象：**地址空间**。
> **地址空间**是一个进程可用于寻址内存的一套地址集合。每一个进程都有一个自己的地址空间，并且这个地址空间独立于其他进程的地址空间。

**基址寄存器与界限寄存器：** 使用**动态重定位**，把每一个进程的地址空间映射到物理内存的不同部分。两个特殊的CPU硬件寄存器
+ 基址寄存器：装载程序的起始物理地址
+ 界限寄存器：装载程序的长度

在进程访问内存时，CPU硬件会首先将基址值加到进程发出的地址值上，同时检查程序提供的地址是否等于或大于界限寄存器中的值。

`缺点：每次访问内存都需要进行加法和比较的运算。加法运算由于进位传递的问题会显得很慢。`

##### 3.2.2 交换技术
如果计算机的物理内存足够大，可以保存所有进程，那么之前所提及的方案或多或少都是可行的。但是很多程序开始处理数据之后可能需要数千兆的空间，所以把所有进程一直保存在内存中需要巨大的内存，如果内存不够大就会导致`内存超载`。

有两种方法处理内存超载：**交换(swapping)技术**，即把进程调用内存中运行一段时间后存回磁盘。另一种是**虚拟内存 (virtual memory)**，使程序在只有一部分被调入内存的情况下运行。

**内存紧缩 (memory compaction)：** 在交换内存的过程中产生了多个空闲区，通过把所有的进程尽可能向下移动，有可能将这些小的空闲区合成一大块。通常不进行这个操作，因为它要耗费大量的CPU时间。 

`问题：如果进程创建时其大小是固定的并且不会改变，则分配很简单。但如果进程需要在堆中动态地分配内存，那么进程空间增长时就面临获取更多空闲空间的问题。`
一种可行的方法是，当换入或移动进程时提前为它分配一些额外的内存供其堆栈段进行增长。

##### 3.2.3 空闲内存管理
在动态分配内存时，操作系统必须对其进行管理。一般有**位图**和**空闲区链表**两种方法。

**1. 使用位图的存储管理**
> 使用位图方法时，内存可能被划分成小到几个字或大到几千字节的分配单元。每个分配单元对应于位图中的一位，0表示空闲，1表示占用（或者相反）。一块内存区和其对应的位图如图3-6所示。
![](https://img-blog.csdnimg.cn/20190414220059645.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxNDc1NzAzOTgw,size_16,color_FFFFFF,t_70)

内存的大小和分配单元的大小决定了位图的大小。这种方法的主要问题是：`在把一个占k个分配单元的进程调入内存时，存储管理器必须所搜位图，在位图中找出k个连续0的串。查找指定长度的连续0串是耗时操作，这时位图的缺点。`

**2. 使用链表的存储管理**
维护一个记录已分配内存段和空闲内存段的链表。其中链表中的一个结点或者包含一个进程，或者是两个进程间的一块空闲区。一个节点包括**空闲区: H** 或者 **进程: P** 的指示标志，**起始地址**，**长度**和**指向下一个节点**的指针。链表使用双向链表可能比单向链表更方便，更易于找到上一个节点。

当按照地址顺序在链表中存放进程和空闲区时，有几种算法可以用来为创建的进程(或从磁盘中换入的已存在的进程)分派内存。
+ **首次适配(first fit)算法:** 沿着段链表从头进行搜索，找到足够大的空闲区域。这种方法速度快。
+ **下次适配(next fit)算法:** 记录每次找到合适空闲区的位置，以便下次寻找空闲区时从上次结束的地方开始搜索。
+ **最佳适配(best fit)算法:** 搜索整个空闲区，找出能够容纳进程的最小空闲区。速度慢且会生成大量无用地小空闲空间。
+ **最差适配(worst fit)算法:** 总是分配最大地可用空闲区，使新的空闲区可以继续使用。
+ **快速适配(quick fit)算法:** 为常用大小的空闲区维护单独的链表。比如链表第一项是指向4kb大小的空闲区的指针，第二项是指向8kb大小的空闲区的指针。快速适配算法能够快速地查找**指定大小的**空闲区。`所有对链表排序的算法都有一个缺点：当一个进程终止或被换出时，寻找它的相邻块并查看是否可以合并的过程是非常费时的(？查看相邻块是否可以合并，如果合并需要重新排序)。如果不进行合并，那内存很快会分裂出大量进程无法使用的小空闲区。`

**对算法速度的优化：** 单独维护进程链表和空闲区链表。这样只用检查空闲区链表，提高算法速度。但会增加复杂度和内存释放速度变慢，因为要将进程链表地回收段删除并插入空闲的区链表。
**对最佳适配算法的优化：** 进程和空闲区使用不同链表，并对空闲区链表按照大小排序，那么最合适的空闲区段就是最小适配的。
**对空闲链表的优化：** 空闲区第一个字可以是空闲区大小，而第二个字可以是指向下一个空闲区的指针。

#### 3.3 虚拟内存
计算机的发展导致运行的程序往往大到内存无法容纳，而且必然需要系统能够支持多个程序同时运行。
20世纪60年代的做法是将整个程序分割成许多片段，称为**覆盖(overlay)**。覆盖块存放在磁盘上，在需要时由操作系统动态地换入换出。问题在于程序员必须把程序分割成多个片段。把一个大程序分割成小的，模块化的片段是非常费时和枯燥的，并且易于出错。

**虚拟内存(virtual memory)：** 虚拟内存的基本思想是，每个程序拥有自己的地址空间，这个空间被分割成多个块，每一块称作一**页**或**页面(page)**。每一页有连续的地址范围。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行。

##### 3.3.1 分页
由程序产生的这些地址成为**虚拟地址(virtual address)**，它们构成了一个**虚拟地址空间(virtual address space)**。
+ 没有虚拟内存的计算机上，系统直接将虚拟地址送到内存总线上，读写操作使用具有同样地址的物理内存字
+ 有虚拟内存的情况下，虚拟地址不是被直接送到内存总线上，而是被送到**内存管理单元(Memory Management Unit, MMU)**，MMU把虚拟地址映射为物理内存地址

虚拟地址空间按照固定大小划分为被称为**页面(page)**的若干单元。在物理内存中对应的单元成为**页框(page frame)**。页面和页框的大小是一样的。

当程序试图访问一个地址时，首先会将虚拟地址送到MMU。MMU看到虚拟地址后，根据其映射结果，将虚拟地址对应的物理地址送到内存总线上。内存对MMU一无所知，它只看到一个读或者写地址的请求并执行它。MMU有效地把虚拟地址映射到了物理地址上。

`但这并没有解决虚拟地址空间比物理内存大的问题。假设物理页框的数量为8，而虚拟页面的数量为16，那么只有8个虚拟页面能够被映射到物理地址上，而其他8个虚拟页面则没有被映射。`
在实际的硬件中，用一个**在/不在 (present / absent bit)位**记录页面在内存中的实际存在情况。

**如果程序访问了一个未被映射的页面，并执行指令时，将会发生什么情况？**
首先虚拟地址将会被送到MMU。MMU发现这个虚拟地址所在的虚拟页面没有物理页框的映射，于是使CPU陷入到系统操作。这个陷阱被成为**页面中断**或**页面错误(page fault)**。操作系统找到一个很少被使用的页框，并把它的内容写入磁盘。随后把需要访问的页面读到刚才回收的页框中，修改映射关系，然后重新启动引起陷阱的指令。

**MMU的工作机制：** 对于16位地址的计算机，其虚拟地址的范围是0到64K-1。假如虚拟页面的大小是4KB，那么总共就有16个虚拟页面。如果虚拟地址是8196，其对应的二进制为 0010000000000100。我们就可以将这个16位的虚拟地址分为4位的页号和12位的偏移量。4位的页号能够表示16个页面，而12位的偏移量可以为一页内的全部4096个字节编址。可用页号作为**页表(page table)** 的索引，以得出对应于该虚拟页面的页框号。如果“在/不在”位是0，则会引起一个操作系统陷阱。如果虚拟页面有对应的物理页面，那么将对应的页框号复制到寄存器的高3位中，同时加上虚拟地址中12位的偏移量。如此就构成了15位的物理地址。

##### 3.3.2 页表
作为最简单的实现，虚拟地址到物理地址的映射可以概括为：虚拟地址被分成虚拟页号(高位部分)和偏移量(地位部分)两部分。对于虚拟地址的划分应对应不同的页面大小。

> 虚拟页号可以作页表的索引，以找到该虚拟页面对应的页表项。由页表项可以找到页框号。然后把页框号拼接到偏移量的高位端，以替换掉虚拟页号，形成送往内存的物理地址。简单来说，页表是一个函数，它的参数是虚拟页号，输出的结果是物理页框号。通过这个函数可以把虚拟地址中的虚拟页面替换成页框域，从而形成物理地址。

**页表项的结构**
![page_table](https://res.cloudinary.com/harlan9613/image/upload/v1585189393/IMG/Page_table_yoxc5z.jpg)
不同计算机的页表项大小可能不一样，但32位是一个常用的大小。最重要的是**页框号**。毕竟页映射的目的是找到这个值，其次是“在/不在”位。这一位是1时表示该表项是有效的，如果是0，表示对应的虚拟页面不在内存中，会引起一个缺页中断。

**保护(protectio)** 位指出一个页允许什么类型的访问。最简单的形式是这个域只有一位，0表示读/写，1表示只读。更先进的方法是使用三位，各位分别对应是否启用读，写，执行该页面。

**修改(modified)** 和**访问(referenced)**位，在写入一页时由硬件自动设置修改位。如果一个页面已经被修改过，则必须把它写回磁盘。如过一个页面没有被修改过，那么只需要简单地丢弃掉就可以了。这一位也被叫做**脏位(dirty)**。

访问位地值用来帮助操作系统在发生缺页中断时选择要被淘汰地页面。不再使用地页面要比正在使用地页面更适合淘汰。访问位在页面置换算法中起到很重要地作用。

##### 3.3.3 加速分页过程
在任何分页系统中，都需要考虑两个主要的问题：
+ 虚拟地址到物理地址地映射必须非常快。
+ 如果虚拟地址空间很大，页表也会很大。

**1. 转换检测缓冲区 (Translation Lookaside Buffer, TLB)：** 是一个为计算机配备地小型硬件设备。将虚拟地址直接映射到物理地址，而不必再访问页表。这个设备通常在MMU中，包含少量地表项。每个表项记录了一个页面地相关信息，包括虚拟页号，页面的修改位，保护码(读，取，执行权限)和该页所对应地物理页框。
![TLB](https://res.cloudinary.com/harlan9613/image/upload/v1585192974/IMG/TLB_mle18e.jpg)

将虚拟地址放入MMU中进行转换时，硬件首先通过将该虚拟页号与TLB中所有表项同时进行匹配，判断该虚拟页面是否在其中。如果发现了一个有效的匹配并且要进行的访问操作并不违反保护位，则将页框号直接从TLB中取出而不必再访问页表。如果虚拟页号确实在TLB中，但指令试图在一个只读页面上进行写操作，则会产生一个错误保护。

如果MMU检测到虚拟页面没有在TLB中，就会进行正常的页表检查。**接着从TLB中淘汰掉一个表项，然后用新找到的页表项代替它**。这样，如果这一个虚拟页表被很快再次访问，第二次访问TLB时就会查询到对应的页框号。被淘汰的页表将修改位复制到内存中的页表项，而除了访问位，其他的值不变。当页表项从页表中装入TLB时。所有的值都来自内存。

**2. 软件TLB管理：**
对TLB的管理和TLB的失效处理都完全由MMU硬件来实现。

许多现在的机器，对页面管理是由软件实现的。TLB表被操作系统显式地装载。
当一个页面访问在内存中而不在TLB时，将产生**软失效(soft miss)**。那么此时要做的就是更新一下TLB。
当一个页面访问即不再内存，也不再TLB时，将产生**硬失效(hard miss)**。此可需要磁盘存取以装入该页面。


##### 3.3.4 针对大内存的页表

**1. 多级页表：**
如果一个32位的虚拟地址被分为10位的PT1域，10位的PT2域和12位的Offset(偏移量)。因为偏移量是12位，所以页面大小是4KB，共有2^20个页面。
> 对于32位的CPU来说，能够寻到的最大地址范围为 2^32 个地址。每个地址访问一个Byte，那么地址范围就是 4294967296 Byte = 4GB。
12位的偏移量指的是能表示的数的范围是 [0] - [2^12 - 1]，那么这个范围就是 2^12 = 4K。一位对应一个字节，所以是4KB。
我们共有4GB范围的地址，每一个分页的范围是4KB，那么总共的页面数就是 4GB / 4KB = 2^20。
那么可以通过前20位来确定在 2^20 个页表中的哪一个页表，然后用12位的偏移来确定具体的位置。

引入多级页表的原因是避免把全部页表一直保存在内存中。特别是那些从不需要的页表就不应该保留。
![page_table2](https://res.cloudinary.com/harlan9613/image/upload/v1585196525/IMG/page_table2_osjooh.jpg)
上图中，左边是顶级页表，有1024个表项，对应于10位的PT1域。当一个虚拟地址被送到MMU时，MMU首先提取PT1域并把该值作为访问顶级页表的索引。因为**4GB** 的虚拟内存空间被分为了**1024** 个表项，那么每一个表项都表示一块**4MB** 的地址范围。

由索引顶级页表得到的表项中含有二级页表的地址或者页框号。**顶级页表的表项0指向程序正文的页表，表项1指向数据的页表，表项1023指向堆栈的页表，其他表项未用。** 现在把PT2域作为访问选定的二级页表的索引，以便找到该虚拟页面的对应页框号。

值得注意的是，虽然图中的虚拟地址超过100万个页面，实际上只需要四个页表：顶级页表，以及正文段，数据段和堆栈段的二级页表。

图中的二级页表可扩充位三级，四级或者多级。级数越多，灵活性就越大。

**2. 倒排页表**


































